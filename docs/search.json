[
  {
    "objectID": "prez/auber_2024/index.html#overview",
    "href": "prez/auber_2024/index.html#overview",
    "title": "[TITLE TBD]",
    "section": "Overview",
    "text": "Overview\n\nIntroduction \nResearch using the latest broadband service data\nChallenges to using the latest broadband service data i.e., More data more problems\nOur broadband data package: cori.data.fcc i.e., How we accelerate innovation by making this complex, ever-changing broadband data more accessible and usable for research"
  },
  {
    "objectID": "prez/auber_2024/index.html#hi-im-olivier-a-senior-data-engineer-at-cori",
    "href": "prez/auber_2024/index.html#hi-im-olivier-a-senior-data-engineer-at-cori",
    "title": "[TITLE TBD]",
    "section": "üëã Hi, I‚Äôm Olivier, a Senior Data Engineer at CORI",
    "text": "üëã Hi, I‚Äôm Olivier, a Senior Data Engineer at CORI\nWorking with source data‚Äîoften referred to as ‚Äúbig‚Äù, ‚Äúmessy‚Äù, ‚Äúunstructured‚Äù data‚Äîis a growing challenge\n\nSource: Harvard Business Review\nSocials: LinkedIn | Mastodon | Personal Website\n\n\nI find ways to add structure and meaning to data so that it can effectively inform the work of the organization‚Äôs analysts, researchers and community managers."
  },
  {
    "objectID": "prez/auber_2024/index.html#coris-mission",
    "href": "prez/auber_2024/index.html#coris-mission",
    "title": "[TITLE TBD]",
    "section": "CORI‚Äôs Mission",
    "text": "CORI‚Äôs Mission"
  },
  {
    "objectID": "prez/auber_2024/index.html#what-broadband-means-to-rural-america",
    "href": "prez/auber_2024/index.html#what-broadband-means-to-rural-america",
    "title": "[TITLE TBD]",
    "section": "What Broadband means to Rural America",
    "text": "What Broadband means to Rural America\n\nWe believe that small towns are home to big ideas ‚Äî and combining new models of economic development with strategic investments in new infrastructure can empower rural communities across the U.S. to participate in and benefit from the nation‚Äôs growing tech economy.\n\nBroadband knowledge is an important part of our work\n\nBroadband data is used extensively in our work to provide critical support to secure funding, develop infrastructure, and implement the programs needed to unlock the potential of rural America."
  },
  {
    "objectID": "prez/auber_2024/index.html#our-broadband-apps-in-the-wild",
    "href": "prez/auber_2024/index.html#our-broadband-apps-in-the-wild",
    "title": "[TITLE TBD]",
    "section": "Our broadband apps in the wild",
    "text": "Our broadband apps in the wild\n\n\nRural Broadband Mapping Tool\n\n\nBroadband Climate Risk Mitigation Tool\n\n\n\nNeed speaker notes with short and sweet takeaways for these two apps"
  },
  {
    "objectID": "prez/auber_2024/index.html#our-broadband-research-from-ideation-to-report",
    "href": "prez/auber_2024/index.html#our-broadband-research-from-ideation-to-report",
    "title": "[TITLE TBD]",
    "section": "Our broadband research: from ideation to report",
    "text": "Our broadband research: from ideation to report"
  },
  {
    "objectID": "prez/auber_2024/index.html#broadband-research-derived-from-cori-data-work",
    "href": "prez/auber_2024/index.html#broadband-research-derived-from-cori-data-work",
    "title": "[TITLE TBD]",
    "section": "Broadband research derived from CORI data work",
    "text": "Broadband research derived from CORI data work\n\n\n\nBeyond connectivity: The role of broadband in rural economic growth and resilience Weinstein, A., Erouart, M., & Dewbury, A. (2024) Beyond Connectivity: The role of broadband in rural economic growth and resilience. Center on Rural Innovation. https://ruralinnovation.us/resources/reports/report-the-role-of-broadband-in-rural-economic-growth-and-resilience/\nThe Fibre Broadband Housing Premium Across Three US States Whitacre, B. (2024). The fibre broadband housing premium across three US States. Regional Studies, Regional Science, 11(1), 38‚Äì62. https://doi.org/10.1080/21681376.2024.2305951"
  },
  {
    "objectID": "prez/auber_2024/index.html#new-findings-from-broadband-research",
    "href": "prez/auber_2024/index.html#new-findings-from-broadband-research",
    "title": "[TITLE TBD]",
    "section": "New findings from Broadband Research",
    "text": "New findings from Broadband Research\n\n‚ÄúBroadband access is increasingly recognized as essential infrastructure in today‚Äôs economy, with the ability to connect residents and businesses to economic opportunities nationwide‚Äù\n\n\nRural counties with high broadband utilization experience:\n\nSignificantly higher business growth rates\nIncreased self-employment growth rates\nHigher per-capita income growth rates\nStronger GDP growth rates\n\n\n\nWeinstein, A., Erouart, M., & Dewbury, A. (2024)\n\n\n\nBroadband access can have a transformative impact on economic growth and resilience, but our research found that access alone is insufficient\nBroadband utilization is a key metric, encompassing both adoption rates and effective leveraging of infrastructure"
  },
  {
    "objectID": "prez/auber_2024/index.html#as-data-experts-solve-data-on-behalf-of-the-researchers",
    "href": "prez/auber_2024/index.html#as-data-experts-solve-data-on-behalf-of-the-researchers",
    "title": "[TITLE TBD]",
    "section": "as data experts: solve data on behalf of the researchers",
    "text": "as data experts: solve data on behalf of the researchers\n\n\n\n\n\nFederal Communications Commission (FCC)\n\n\n\n\n\n\n\nForm 477\nNational Broadband Map\n\n\n\n\nUS Census Boundaries\n2010\n2020\n\n\nGranularity\nCensus blocks\nLocations\n\n\nTimeframe\n2014-2021\n2022 - Ongoing\n\n\nReleases\ntwice a year\ntwice a year[^version]\n\n\nRecords\n416,447,807\n3,488,191,994\n\n\nSize\n400MB/year\n22GB/year\n\n\n\n\n\nBig messy data\nRecquire domain knowledge\nEvolving data landscape\n\n\n\n\n\nAgency in charge of regulating ‚Äúeverything‚Äù communications\nTheir data landscape is evolving fast (now they have a platform!)\n\nHow to work with constant change upstream?\nThese datasets are voluminous, involving hundreds of files, especially for the Form 477 data which covers ISP data since 2014\nFCC releases lack ‚Äúguard rails‚Äù in terms of data quality and consistency. In addition to publishing very meager change logs (based on CostQuest‚Äôs pre-release/proprietary updates), issues include multiple encodings, erroneous values, and limited quality control\nAnalysis of the National Broadband Map (NBM) data reveals inconsistencies and potential errors in key identifiers like the FCC Registration Number (FRN), Provider ID, and Brand Name: * Different FRNs and Provider IDs are used for the same ISP (‚ÄúEATEL Corp.‚Äù) The same Provider ID is associated with different FRNs (Acentek). Multiple FRNs exist for well-known ISPs like Windstream and AT&T."
  },
  {
    "objectID": "prez/auber_2024/index.html#how-you-would-use-the-fccs-dataplatform",
    "href": "prez/auber_2024/index.html#how-you-would-use-the-fccs-dataplatform",
    "title": "[TITLE TBD]",
    "section": "How you would use the FCC‚Äôs data/platform‚Ä¶",
    "text": "How you would use the FCC‚Äôs data/platform‚Ä¶\n\n\nVideo\n\n\nüîÅ Repeat for every State (56)\nüîÅ Repeat for every version (??)\nüî¥ Error prone (500 hundred clicks)"
  },
  {
    "objectID": "prez/auber_2024/index.html#as-a-broadband-researcher",
    "href": "prez/auber_2024/index.html#as-a-broadband-researcher",
    "title": "[TITLE TBD]",
    "section": "As a broadband researcher,",
    "text": "As a broadband researcher,\n\nI wish I didn‚Äôt have to manually download FCC data\nI wish I could share my analysis (and code) with colleagues\nI wish I could easily perform quality checks on the raw FCC data\n\n‚Ä¶ I wish I had more time to do the interesting research and analysis"
  },
  {
    "objectID": "prez/auber_2024/index.html#light-from-positconf-slack-is-buzzing",
    "href": "prez/auber_2024/index.html#light-from-positconf-slack-is-buzzing",
    "title": "[TITLE TBD]",
    "section": "üí° Light from posit::conf, Slack is buzzing!",
    "text": "üí° Light from posit::conf, Slack is buzzing!\nWorkshop on DuckDB (Parquet / Arrow / OLAP)\n\n\n\n\n\n\nWarning\n\n\nContains real slack messages with typos!"
  },
  {
    "objectID": "prez/auber_2024/index.html#data-packaged-as-code",
    "href": "prez/auber_2024/index.html#data-packaged-as-code",
    "title": "[TITLE TBD]",
    "section": "‚Ä¶ data packaged as code",
    "text": "‚Ä¶ data packaged as code\n\n\nAddress Data Challenges\n\n\nData is packaged as code to simplify data access, reduce errors, and promote collaboration.\nLow-level data transformations are codified: easy for others to reproduce.\n\n\nAccelerate Innovation\n\n\nBroadband data is packaged so that researchers can focus on analysis and insights, not data wrangling.\n\n\nUnlock Deeper Insights Faster\n\n\ncori.data.fcc provides fast access to granular details, essential for understanding broadband challenges across multiple geographic scales.\n\n\n\n\npackages can act like team members such as the IT Guy, Analyst, Tech Lead, or Project Manager.\n\n\n\npromote collaboration: open source, more value from our codes, start discussion with upstream, USAC"
  },
  {
    "objectID": "prez/auber_2024/index.html#how-it-works",
    "href": "prez/auber_2024/index.html#how-it-works",
    "title": "[TITLE TBD]",
    "section": "‚Ä¶ how it works",
    "text": "‚Ä¶ how it works\n\n\n\nVisualCode\n\n\nVideo\n\n\n\nlibrary(cori.data.fcc)\n\ndir &lt;- \"data_swamp/nbm/\"\n\nget_nbm_release()\n\nnbm_data &lt;- get_nbm_available()\n\nsystem(sprintf(\"mkdir -p %s\", dir))\n\ndl_nbm(\n  path_to_dl = \"data_swamp/nbm\",\n  release_date = \"June 30, 2023\",\n  data_type = \"Fixed Broadband\",\n  data_category = \"Nationwide\",\n)\n# part to check if dl was successful\nnum_files &lt;- get_nbm_available() |&gt;\n  dplyr::filter(release == \"June 30, 2023\" &\n                data_type == \"Fixed Broadband\" &\n                data_category == \"Nationwide\") |&gt;\n  nrow()\n\nfiles_dl &lt;- length(list.files(dir,\n                              pattern = \"*.zip\"))\n\nidentical(num_files, files_dl)\n# TRUE\n\n\n\n\n\n\n¬†\n\n\n\nAdded DuckDB\nCreated quality checks to reduce errors\nComplexity is handled in our upstream process and abstracted so that users can focus on what brings value!\n\n\n\nDuckDB unlocked in-process analytics, so access to a database management system/server is no longer required in order to explore and use the data"
  },
  {
    "objectID": "prez/auber_2024/index.html#how-to-use-the-package-choose-your-own-adventure",
    "href": "prez/auber_2024/index.html#how-to-use-the-package-choose-your-own-adventure",
    "title": "[TITLE TBD]",
    "section": "How to use the package > Choose your own adventure!",
    "text": "How to use the package &gt; Choose your own adventure!\n\n\nBroadband data at the census block (or tract, county, etc.) level is perfect for my research: ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† Download the transformed data for NBM from CORI (ISP / County)\nI need to inspect the source (raw) data: Download raw data files directly from the FCC\nI need source data but working with hundreds of CSV is not for me: Download raw data as tables from CORI (NBM / Form 477)\nThe guides linked above can help you with each step!"
  },
  {
    "objectID": "prez/auber_2024/index.html#broadband-service-in-the-northeast-kingdom",
    "href": "prez/auber_2024/index.html#broadband-service-in-the-northeast-kingdom",
    "title": "[TITLE TBD]",
    "section": "Broadband service in the Northeast Kingdom",
    "text": "Broadband service in the Northeast Kingdom\n\n\n\nVisualCode\n\n\n\n\n\n\nlibrary(cori.data.fcc); library(dplyr); library(sf); library(tigris)\nlibrary(ggplot2); library(cori.charts); library(basemapR)\n\ncori.charts::load_fonts()\n\ncaledonia_co_nbm &lt;- cori.data.fcc::get_nbm_bl(geoid_co = \"50005\")\nessex_co_nbm &lt;- cori.data.fcc::get_nbm_bl(geoid_co = \"50009\")\norleans_co_nbm &lt;- cori.data.fcc::get_nbm_bl(geoid_co = \"50019\")\n\nnek_nbm &lt;- dplyr::bind_rows(caledonia_co_nbm, essex_co_nbm, orleans_co_nbm)\n\n# tigris to get places and block\nvt_blocks &lt;- tigris::blocks(\"VT\", progress_bar = FALSE)\nvt_places &lt;- tigris::places(state = \"VT\", progress_bar = FALSE)\n\n# wrangling\nnek_bb_blocks &lt;- inner_join(\n    vt_blocks,\n    nek_nbm,\n    by = c(\"GEOID20\" = \"geoid_bl\")\n  ) |&gt;\n  mutate(\n    pct_100_20 = cnt_100_20 / cnt_total_locations,\n    pct_fiber = cnt_fiber_locations / cnt_total_locations\n  )\n\n# Get major NEK Place centroids for map labeling\nvt_places_centroids &lt;- vt_places[lengths(sf::st_intersects(vt_places, nek_bb_blocks)) &gt; 0, ] |&gt;\n  st_centroid()\n\n# Map\nbbox &lt;- sf::st_bbox(nek_bb_blocks) |&gt;\n        cori.charts::fit_bbox_to_aspect_ratio(target_aspect_ratio = 2)\n\nfig &lt;- ggplot(data = nek_bb_blocks) +\n  base_map(\n    bbox,\n    increase_zoom = 3,\n    basemap = 'voyager'\n  ) +\n  geom_sf(aes(fill = pct_100_20), color = \"dimgray\", linewidth = 0.1, alpha = 0.9) +\n  scale_fill_cori(\n    discrete = FALSE,\n    palette = \"ctg2pu\",\n    labels = scales::label_percent(),\n    reverse = T\n  ) +\n  geom_sf_label(data = vt_places_centroids, aes(label = NAME), size = 2, color = \"black\", family = \"Lato\", fontface = \"bold\") +\n  coord_sf(\n    expand = TRUE,\n    xlim = c(bbox['xmin'], bbox['xmax']),\n    ylim = c(bbox['ymin'], bbox['ymax'])\n  ) +\n  theme_cori_map() +\n  theme(\n    legend.key.width = unit(50, \"pt\")\n  ) +\n  labs(\n    title = \"Broadband service in the Northeast Kingdom\",\n    subtitle = \"Percent of locations with access to 100/20 Mbps service by census block\",\n    caption = \"Data source: 2023 FCC National Broadband Map\\nMap source: ¬© OpenStreetMap contributors ¬© CARTO\",\n    x = NULL,\n    y = NULL\n  )\n\n\n\n\n\n\n¬†\n\n\n\nBetter services closer to ‚Äúmain street‚Äù (and worst farther‚Ä¶)\n3 lines of codes to get the data\nUse census blocks: easy match with other data sources (ACS, BEA, etc ..)"
  },
  {
    "objectID": "prez/auber_2024/index.html#northeast-kingdom-only-11.5-of-locations-have-fiber",
    "href": "prez/auber_2024/index.html#northeast-kingdom-only-11.5-of-locations-have-fiber",
    "title": "[TITLE TBD]",
    "section": "Northeast Kingdom: only 11.5% of locations have fiber",
    "text": "Northeast Kingdom: only 11.5% of locations have fiber\n\n\n\nVisualCode\n\n\n\n\n\n\nfig &lt;- ggplot(data = nek_bb_blocks) +\n  base_map(\n    bbox,\n    increase_zoom = 3,\n    basemap = 'voyager'\n  ) +\n  geom_sf(aes(fill = pct_fiber), color = \"dimgray\", linewidth = 0.1, alpha = 0.6) +\n  scale_fill_cori(\n    discrete = FALSE,\n    palette = \"ctg2pu\",\n    labels = scales::label_percent(),\n    reverse = T\n  ) +\n  geom_sf_label(data = vt_places_centroids, aes(label = NAME), size = 2, color = \"black\", family = \"Lato\", fontface = \"bold\") +\n  coord_sf(\n    expand = TRUE,\n    xlim = c(bbox['xmin'], bbox['xmax']),\n    ylim = c(bbox['ymin'], bbox['ymax'])\n  ) +\n  theme_cori_map() +\n  theme(\n    legend.key.width = unit(50, \"pt\"),\n  ) +\n  labs(\n    title = \"Fiber access in the Northeast Kingdom\",\n    subtitle = \"Percent of locations with access to fiber by census block\",\n    caption = \"Data source: 2023 FCC National Broadband Map\\nMap source: ¬© OpenStreetMap contributors ¬© CARTO\",\n    x = NULL,\n    y = NULL\n  )\n\n\n\n\n\n\n¬†\n\n\n\nOnly 11.5% of locations have fiber access in the Northeast Kingdom\n6/25 ISP are providing Fiber\nLeading ISP here is small ISP, non-profit: NEK broadband"
  },
  {
    "objectID": "prez/auber_2024/index.html#what-are-each-isp-competitors-in-ohio",
    "href": "prez/auber_2024/index.html#what-are-each-isp-competitors-in-ohio",
    "title": "[TITLE TBD]",
    "section": "What are each ISP competitors in Ohio?",
    "text": "What are each ISP competitors in Ohio?\n\n\n\nVisualCode\n\n\n\n\n\n\n\n\n\n\n\nlibrary(tigris);library(cori.data.fcc);library(igraph);library(dplyr)\nlibrary(crosstalk);library(DT);library(threejs)\n\noh &lt;- tigris::counties(state = \"39\") # tigris is a great example of data as code\n\ntalk_to_me &lt;- function(x) {\n    message(sprintf(\"Love Ohio: %s\", x))\n    cori.data.fcc::get_nbm_bl(x)\n}\noh_nbm &lt;- lapply(oh$GEOID, talk_to_me) |&gt; dplyr::bind_rows()\n\noh2_nbm &lt;- oh_nbm[!is.na(oh_nbm$combo_frn), ]\n\nod_me &lt;- function(x) {\n\n  temp &lt;- oh2_nbm[x, \"array_frn\"][[1]]\n  geoid_bl &lt;- oh2_nbm[x, \"geoid_bl\"]\n  if (length(temp) == 1L)\n  {\n    return(data.frame(V1 = temp, V2 = NA, geoid_bl = geoid_bl))\n  }\n  bob &lt;- as.data.frame(t(combn(temp, 2)))\n  bob$geoid_bl &lt;- geoid_bl\n  return(bob)\n}\n\nod &lt;- lapply(1:nrow(oh2_nbm), od_me) |&gt; dplyr::bind_rows()\nod &lt;- od[!is.na(od$V2),]\n\nbob &lt;- rbind(data.frame(frn = od$V1, geoid_bl = od$geoid_bl),\n             data.frame(frn = od$V2, geoid_bl = od$geoid_bl))\n\ncnt_bl &lt;- summarise(bob, cnt_bl = n_distinct(geoid_bl), cnt_rel = n(), .by = frn)\n\nod &lt;- od[!is.na(od$V2),]\n\nod$combo &lt;- paste(od$V1, od$V2, sep = \" - \")\nod$count &lt;- 1\n\nrel &lt;- od |&gt; dplyr::summarize(n = sum(count), .by = combo)\ngive_me_from &lt;- function(x) unlist(strsplit(x, \" - \"))[1]\ngive_me_to &lt;- function(x) unlist(strsplit(x, \" - \"))[2]\nrel$from &lt;- sapply(rel$combo , give_me_from)\nrel$to &lt;- sapply(rel$combo, give_me_to)\n\nfcc_slim &lt;- cori.data.fcc::fcc_provider[, c(\"frn\", \"provider_name\")]\nfrn &lt;- data.frame( frn = unique(c(rel$from, rel$to)))\nfrn &lt;- merge(frn, fcc_slim, by.x = \"frn\", by.y = \"frn\")\nfrn &lt;- merge(frn, cnt_bl, by.x = \"frn\", by.y = \"frn\")\n\noh_graph &lt;- graph_from_data_frame(rel[,c(\"from\", \"to\")], directed = FALSE, vertices = frn)\n\noh_graph &lt;- graph_from_data_frame(rel[,c(\"from\", \"to\")], directed = FALSE, vertices = frn)\n\ndraw_me_a_graph &lt;- function(x, ...) {\n  threejs::graphjs(x,\n          vertex.label = V(x)$provider_name,\n          vertex.color = rep(2, vcount(x)),\n          vertex.size = .1,\n          edge.color = \"grey\",\n          edge.width = 3, ...)\n}\n\ng &lt;- draw_me_a_graph(oh_graph, brush=TRUE)\npoints3d(g, vertices(g), color=\"black\", pch=V(oh_graph)$provider_name, size=1.5)\n\n\n\n\n\n\n¬†\n\n\n\n1321 ISP operating in Ohio\nProviders competiting in all Ohio are at the core\nProviders with few competitors are at the edges\ncori.data.fcc support spatial and graph data"
  },
  {
    "objectID": "prez/auber_2024/index.html#how-to-get-the-package",
    "href": "prez/auber_2024/index.html#how-to-get-the-package",
    "title": "[TITLE TBD]",
    "section": "How to get the package",
    "text": "How to get the package\nThe source code is hosted on GitHub (Version control)\nYou need the R package {remotes}.\n\ninstall.packages(\"remotes\")\nremotes::install_github(\"ruralinnovation/cori.data.fcc\")\n\nüöß Check the version you have and see what new versions are available üöß\n\npackageVersion(\"cori.data.fcc\")\n\n[1] '0.0.1'"
  },
  {
    "objectID": "prez/auber_2024/index.html#summary-data-is-only-useful-if-you-can-effectively-use-it.",
    "href": "prez/auber_2024/index.html#summary-data-is-only-useful-if-you-can-effectively-use-it.",
    "title": "[TITLE TBD]",
    "section": "Summary: Data is only useful if you can effectively use it.",
    "text": "Summary: Data is only useful if you can effectively use it.\n\n\nData packages are abstracting the pain\nData packages can give more power (especialy )!\nIn emerging field: Easier to capitalize/build on it\nWe need those extra ‚Äúteam members‚Äù"
  },
  {
    "objectID": "prez/auber_2024/index.html#slides-are-online",
    "href": "prez/auber_2024/index.html#slides-are-online",
    "title": "[TITLE TBD]",
    "section": "Slides are online:",
    "text": "Slides are online:\n\nBuilt with R and cori.data.fcc\nCreated by Quarto (format: revealjs)\nHosted and deployed on GitHub https://ruralinnovation.github.io/prez_auber_2024/"
  },
  {
    "objectID": "prez/auber_2024/index.html#contacts",
    "href": "prez/auber_2024/index.html#contacts",
    "title": "[TITLE TBD]",
    "section": "Contacts",
    "text": "Contacts\nWebsite: https://ruralinnovation.us\nLinkedIn | Twitter | Facebook | Instagram | YouTube"
  },
  {
    "objectID": "prez/urisa_2023/index.html#our-slides-are-online",
    "href": "prez/urisa_2023/index.html#our-slides-are-online",
    "title": "Extending Broadband to Underserved Areas",
    "section": "Our slides are online:",
    "text": "Our slides are online:\nSlides realized in Quarto hosted in GitHub\nData stack: SQL (PostgreSQL), R with DBI, targets, ggplot2 and ‚Äúin house‚Äù packages\n\n\n\n\n\nhttps://ruralinnovation.github.io/conf_URISA_2023/#/title-slide"
  },
  {
    "objectID": "prez/urisa_2023/index.html#who-are-we",
    "href": "prez/urisa_2023/index.html#who-are-we",
    "title": "Extending Broadband to Underserved Areas",
    "section": "Who are we?",
    "text": "Who are we?\n\n\n\nOlivier üá®üáµ Senior Data Engineer\n\n\nDrew üá∫üá∏ Lead Data Scientist\n\n\n@drew"
  },
  {
    "objectID": "prez/urisa_2023/index.html#center-on-rural-innovation-cori",
    "href": "prez/urisa_2023/index.html#center-on-rural-innovation-cori",
    "title": "Extending Broadband to Underserved Areas",
    "section": "Center On Rural Innovation (CORI)",
    "text": "Center On Rural Innovation (CORI)\nAdvancing economic prosperity in rural America through the creation of inclusive tech economy ecosystem that support scalable entrepreneurship and tech job creation\n\n\nLearn more at: https://ruralinnovation.us/\n\n\nWhere does Broadband stand in CORI goals Here the focus is Broadband is an ingredient of tech ecosystem\nFCC staff estimates:\nWhy we like it:\n\nDataset provided for both 2010 and 2020 US census boundaries\nFCC provides their methodology and codes\nSame institution that NBM and F477\nProvides estimates for housing units"
  },
  {
    "objectID": "prez/urisa_2023/index.html#defining-rural",
    "href": "prez/urisa_2023/index.html#defining-rural",
    "title": "Extending Broadband to Underserved Areas",
    "section": "Defining Rural",
    "text": "Defining Rural\n\n\n‚ÄúRural‚Äù refers to the ‚Äúnonmetro plus‚Äù definition: includes all nonmetro counties and all tracts classified as RUCA 4 or higher.\nUSDA‚Äôs Rural-Urban Community Area (RUCA) codes categorize rural areas by population density, urbanization, and daily commuting.\nMore nuanced rural definition, classifying rural places along a continuum.\nCombining definitions: better encapsulates places that are rural in character.\n\n\n\n\n\n\n\nFor more information see Defining rural America: The consequences of how we count.\n\n\n@drew"
  },
  {
    "objectID": "prez/urisa_2023/index.html#historical-and-new-data-context",
    "href": "prez/urisa_2023/index.html#historical-and-new-data-context",
    "title": "Extending Broadband to Underserved Areas",
    "section": "Historical and new data context",
    "text": "Historical and new data context\n\nFederal Communications Commission: FCC\nForm 477: F477\nNational Broadband Map: NBM\nUnserved: less than 25/3 Mbps downloads/uploads\n\n\n\n\n\nF477\nNBM\n\n\n\n\nUS Census Boundaries\n2010\n2020\n\n\nType of recording\nself declarative\nself declarative\n\n\nGranularity\nCensus block\nLocations\n\n\nServices\nMobile/Fixed\nMobile/Fixed\n\n\nReleases\n2014-2021\n2022 - Ongoing\n\n\n\nF477: ‚Äúat least one‚Äù rule\nNBM‚Äôs BEAD definitions for Unserved area: an area in which not less than 80 percent of broadband-serviceable locations are unserved locations.\n\nsome BB defs here should we add an iframe of some FCC NBM localisation?\n@drew is it 2014?\nat least one rule: if one ISP said he was present with 25/3 in a census block then all location in that block was ‚ÄúServed‚Äù"
  },
  {
    "objectID": "prez/urisa_2023/index.html#whats-on-the-table",
    "href": "prez/urisa_2023/index.html#whats-on-the-table",
    "title": "Extending Broadband to Underserved Areas",
    "section": "What‚Äôs on the table",
    "text": "What‚Äôs on the table\n\n\nBroadband Equity Access and Deployment (BEAD) Program provides $42.45B to expand high-speed internet access by planning, infrastructure deployment, and adoption programs\nMinimum BEAD allocations range from $25M (US territories) to $100M (states and Puerto Rico)\nRemaining BEAD allocations vary across states depending on the number and concentration of unserved locations\n\n\n\n\n\ndrew\n\n\nSource: PEW / State specific funding"
  },
  {
    "objectID": "prez/urisa_2023/index.html#bead-priorities",
    "href": "prez/urisa_2023/index.html#bead-priorities",
    "title": "Extending Broadband to Underserved Areas",
    "section": "BEAD Priorities",
    "text": "BEAD Priorities\n\n\nCoverage\nPrimary goal is to extend broadband internet service (‚â• 25Mbps/3Mbps) to all\nTechnology\nPrioritizes projects designed to provide fiber connectivity directly to the end user\nAffordability\nPrioritizes projects that aim at improving affordability of service\n\n\n\n\n\nSource: BEAD NOFO"
  },
  {
    "objectID": "prez/urisa_2023/index.html#workflow-from-fcc-to-our-products",
    "href": "prez/urisa_2023/index.html#workflow-from-fcc-to-our-products",
    "title": "Extending Broadband to Underserved Areas",
    "section": "Workflow: From FCC to our products",
    "text": "Workflow: From FCC to our products\n\n\n\n\n\n%%{init: {'theme': 'base', 'themeVariables': { 'fontSize': '20px', 'fontFamily': 'Bitter'}}}%%\nflowchart LR\n    A1[FCC Website] --&gt; B1[Server]\n    A2[TIGER Census block] --&gt; C2\n    subgraph Ingestion\n    direction TB\n    B1--&gt; B2[Data Wrangling]\n    B2--&gt; B3[Populate source DB]\n    end\n    subgraph Transform\n    direction TB\n    C1[Remove Sat.]--&gt; C2[Count Services]\n    C2 --&gt; C3[Blocks DB]\n    end\n    subgraph Serving\n    direction TB\n    D1[Prod. Server] --&gt; D2[Analytic Tables]\n    end\n    Ingestion --&gt; Transform\n    C3 --&gt; D1\n    D1--&gt; E1[Tools: &lt;Br&gt; Public CH &lt;BR&gt; Internal BCAT]\n    D2--&gt; E1\n    D2 --&gt; E4[Data team &lt;BR&gt; Broadband team]\n    D2 --&gt; E5[URISA]\n    click E1 \"https://broadband-risk.ruralinnovation.us/\" _parent\n    click E5 \"https://ruralinnovation.github.io/conf_URISA_2023/#/workflow-from-fcc-to-our-products\" _parent\n    style Ingestion fill:#fff\n    style Transform fill:#fff\n    style Serving fill:#fff\n\n\n\n\n\n\n\nTwo releases per year (but 7 versions of Dec.¬†2022 releases)\n440 files for 11GB zipped (Fixed)\nThis presentation uses FCC staff estimates\n\n\n\nTools used: Shell (Bash) with GNU tools (make, csvkit, sed) and GDAL / SQL (PostgreSQL/PostGIS) / A bit of R (ease some processes)"
  },
  {
    "objectID": "prez/urisa_2023/index.html#results-at-the-us-level",
    "href": "prez/urisa_2023/index.html#results-at-the-us-level",
    "title": "Extending Broadband to Underserved Areas",
    "section": "Results: At the US level",
    "text": "Results: At the US level\n\nNot Reported - UnservedFiber access - 100/20 MBps\n\n\n\n\n\n\n\n\n\n\n@olivier"
  },
  {
    "objectID": "prez/urisa_2023/index.html#rural-areas-overrepresented-in-poor-quality-broadband",
    "href": "prez/urisa_2023/index.html#rural-areas-overrepresented-in-poor-quality-broadband",
    "title": "Extending Broadband to Underserved Areas",
    "section": "Rural areas Overrepresented in poor quality broadband!",
    "text": "Rural areas Overrepresented in poor quality broadband!\n\nNBMF477\n\n\n\n\n\n\n\n\n\n\n@olivier Observation about f477 -&gt; NBM in US is similar in rural but ‚Äúamplifed‚Äù\nRural has a worth bb access: * more Not Reported / Unserved. * less coverage, especialy fiber."
  },
  {
    "objectID": "prez/urisa_2023/index.html#rural-areas-underestimated-in-statistics",
    "href": "prez/urisa_2023/index.html#rural-areas-underestimated-in-statistics",
    "title": "Extending Broadband to Underserved Areas",
    "section": "Rural Areas underestimated in statistics",
    "text": "Rural Areas underestimated in statistics\n\nPicking a 50% threshold can help close the gap!"
  },
  {
    "objectID": "prez/urisa_2023/index.html#conclusions",
    "href": "prez/urisa_2023/index.html#conclusions",
    "title": "Extending Broadband to Underserved Areas",
    "section": "Conclusions",
    "text": "Conclusions\n\n\n\n\n\n\n\nWhile nonrural access to broadband has exceeded 94% since 2014, rural broadband access stood at just 65% in 2014 and only reached 92% in 2020.\n\n\n\nOverall great improvement in data quality and better understanding on what is happening on the ground (is it enough?)\nRural areas are still overrepresented in poor quality broadband\nRural areas are systematically underestimated by data definitions\n\n\n\n\n@drew even if we use the tabulate 2010 2020 we will face some issues: where are the locations in % covered of x 2020 or y 2020 block"
  },
  {
    "objectID": "prez/urisa_2023/index.html#next-steps",
    "href": "prez/urisa_2023/index.html#next-steps",
    "title": "Extending Broadband to Underserved Areas",
    "section": "Next steps",
    "text": "Next steps\nWhat are we measuring? An improvement on coverage, an improvement on data quality or both?\n\n\nGetting better at counting people (use Housing Units, Microsoft building footprint, ACS)\nGetting better at estimating locations (optimize the cost of building broadband infrastructure)\n\n\nIndividual can provides ground level recording from their location (challenges)\nFabric data\nUpcoming FCC updates (API?)\n\n\nSharing our results: Providing a reproducible way for others to explore FCC data at scale"
  },
  {
    "objectID": "prez/urisa_2023/index.html#contacts",
    "href": "prez/urisa_2023/index.html#contacts",
    "title": "Extending Broadband to Underserved Areas",
    "section": "Contacts",
    "text": "Contacts\n\n\nOlivier Leroy\nüìß: olivier.leroy@ruralinnovations\nLinkedIn\n\nDrew Rosebush\nüìß: drew.rosebush@ruralinnovation.us\nLinkedIn\n\n\n\n\nWebsite: https://ruralinnovation.us\nLinkedIn | Twitter | Facebook | Instagram | YouTube"
  },
  {
    "objectID": "prez/urisa_2023/index.html#check-out-our-bead-climate-tool",
    "href": "prez/urisa_2023/index.html#check-out-our-bead-climate-tool",
    "title": "Extending Broadband to Underserved Areas",
    "section": "Check out our BEAD Climate Tool",
    "text": "Check out our BEAD Climate Tool\n\n\n\n\n\n\nhttps://broadband-risk.ruralinnovation.us/#about"
  },
  {
    "objectID": "posts/05_micropolitan_formd/index.html",
    "href": "posts/05_micropolitan_formd/index.html",
    "title": "The top 10 micropolitan areas for raising venture capital",
    "section": "",
    "text": "Venture capital funding plays a pivotal role in bolstering a region‚Äôs economy by catalyzing innovation, fostering job creation, and attracting talent.\nVenture capital investment injects vital funding into promising businesses with growth potential, enabling them to scale rapidly. And it holds immense promise for revitalizing rural America‚Äôs economy by empowering local entrepreneurs with the resources needed to innovate and grow.\nThough rural areas have traditionally been overlooked by investors, many rural entrepreneurs have managed to access capital that is crucial to transforming their budding ideas into thriving businesses.\nTo explore the venture capital landscape in rural America, we can use the SEC‚Äôs Form D to identify the amount of funding received by private businesses in micropolitan areas. A micropolitan area, as defined by the U.S. Office of Management and Budget, is a region centered around a small urban cluster with a population between 10,000 and 50,000 people. These areas are smaller than metropolitan areas but still exhibit economic and social connections with nearby population centers, making micropolitans an ideal geography for observing venture capital dynamics in rural economies.\n\n\n\n\n\n\nHere are the micropolitan areas that raised the most venture capital in 2022:\n\n\nAnd here are the micropolitan areas that raised the most in venture capital funding per capita in 2022:\n\n\n\n\n\n\n\nMicro VC totals (click chart to enlarge)\n\n\n\n\n\n\n\nMicro VC chart (click chart to enlarge)\n\n\n\n\n\n\nSheridan, Heber, and Jackson achieved these outcomes through an abundance of venture capital activity, while the others are driven by a couple companies with very large deals in 2022.\nOf the 81 micropolitans that raised venture capital through Regulation D in 2022, the 10 that raised the most represent 84% of the $1.4 billion in funding that went to micropolitan areas.\n\nThe 10 micropolitans with the most funding per capita varied widely by population size. Grants, New Mexico, had the smallest population (11,620), while the population of Bozeman, Montana, (109,207) was much larger than the others on this list. Heber, Utah was the second-largest micropolitan area in the top 10 (68,075).\n\nEach of these micropolitan areas demonstrates that rural communities are ripe with entrepreneurial spirit and offer investors an abundance of opportunities.\nIf you‚Äôd like to dig deeper on the power of direct investment in rural startups, check out our seed fund, the CORI Innovation Fund, which has a growing portfolio of rural tech startups with high-growth potential. Or you can connect with our team directly to learn more!"
  },
  {
    "objectID": "posts/03_urisa-2023/index.html",
    "href": "posts/03_urisa-2023/index.html",
    "title": "MDA‚Äôs URISA-2023 presentation",
    "section": "",
    "text": "The Urban and Regional Information Systems Association ‚Äî better known as URISA ‚Äî is the main association for professionals in the GIS and geospatial space.\nWe were fortunate enough to be selected to present a portion of our work on broadband infrastructure at URISA‚Äôs annual conference GIS-Pro-2023 last fall in Columbus, Ohio.\nOur presentation, ‚ÄúRural areas are overrepresented in unserved areas and underestimated in statistics,‚Äù utilized FCC NBM data to demonstrate several points:\n\nThe new dataset (NBM) represents an improvement over the previous one (derived from F477).\nDespite the narrowing gap between rural and nonrural areas, significant disparities still exist.\nThe current BEAD definition of an ‚Äúunserved area‚Äù is less suitable for rural areas than for urban areas.\n\nYou can dig more into our presentation HERE!"
  },
  {
    "objectID": "posts/01_awesomejq/index.html",
    "href": "posts/01_awesomejq/index.html",
    "title": "Awesome jq and GeoJSON",
    "section": "",
    "text": "If you are manipulating a lot of GeoJSON features/objects and want a quick CLI tool to filter and slice them, you should give jq a try! Since there are not many tutorials that exist on using jq to manage objects in the GeoJSON family, we hope that these few tricks will help you on your learning journey.\nIn these examples, we are using a GeoJSON file of Vermont census blocks with attributes related to our work on broadband data. While it is not a deeply nested JSON, it is perfect to illustrate some common use cases.\nA quick check lets us know that it is 94 MB. Not ‚Äúthat‚Äù big but still decent.\nFirst, let‚Äôs see how many features it has. Here‚Äôs how we can approximate that:\nThis is a decent estimate, but we are counting some rows at the top and bottom of the file that are not features (try head -n 5 and tail on it if you are curious).\nWe can also use jq:\nThis is the correct number of blocks! How did that magic work? Let‚Äôs decompose our one-liner:"
  },
  {
    "objectID": "posts/01_awesomejq/index.html#jq-and-small-examples",
    "href": "posts/01_awesomejq/index.html#jq-and-small-examples",
    "title": "Awesome jq and GeoJSON",
    "section": "jq and small examples",
    "text": "jq and small examples\nIt is always a good idea to start experimenting with smaller data so let‚Äôs start there:\njq '.features[0:5]'  data/vt-bb.geojson &gt; data/not_perfect_sample.geojson\nHere we asked for the [0 to 5[ (yes: [inclusive:exclusive]) features (i.e.¬†the first 5) and jq produces a valid JSON but if you inspect it you will see that we moved from GeoJSON to a JSON array.\njq '.' data/not_perfect_sample.geojson | head -n 4\n# [\n#   {\n#     \"type\": \"Feature\",\n#     \"properties\": {\n# to compare with :\njq '.' data/vt-bb.geojson | head -n 12/\n# { \n#   \"type\": \"FeatureCollection\",\n#   \"name\": \"sql_statement\",\n#   \"crs\": {\n#     \"type\": \"name\",\n#     \"properties\": {\n#       \"name\": \"urn:ogc:def:crs:EPSG::4269\"\n#     }\n#   },\n#   \"features\": [\n#     {\n#       \"type\": \"Feature\",\nWe used .features so jq returned the following value (here an array with all the features) but we lost type, name, and crs.\nYou probably have noticed that . is used to return all the input as output but by default jq will prettify the JSON.\nIf we want to keep them we will need to be slighly more verbose:\njq '{type: .type , crs: .crs ,features: .features[0:10]}' data/vt-bb.geojson &gt; data/better_sample.geojson \nHere we introduced {} allowing you to build a JSON object. We then ‚Äústick them‚Äù together and send them to a new JSON with a proper type and crs (grabbed from our original file)."
  },
  {
    "objectID": "posts/01_awesomejq/index.html#extracting-geometries",
    "href": "posts/01_awesomejq/index.html#extracting-geometries",
    "title": "Awesome jq and GeoJSON",
    "section": "Extracting geometries!",
    "text": "Extracting geometries!\nIf we just want the geometries of our census blocks:\njq '{type: .type , crs: .crs ,features: [.features[] | del(.properties)]}' better_sample.geojson &gt; sample_only_geom.geojson  \nHere we are streaming a filter on .features[] into a function that will delete all properties (del(.properties)) and this will be used as an array for features.\nWe will need to adjust that code a bit for data/vt-bb.geojson:\njq --compact-output  '{type: .type , crs: .crs ,features: [.features[] | del(.properties)]}'  data/vt-bb.geojson &gt; data/geom.geojson\n--compact-output will convert to a single line JSON (and saved space!). Now data/geom.geojson is 72MB."
  },
  {
    "objectID": "posts/01_awesomejq/index.html#jq-please-give-me-a-data-frame",
    "href": "posts/01_awesomejq/index.html#jq-please-give-me-a-data-frame",
    "title": "Awesome jq and GeoJSON",
    "section": "jq , please give me a data frame:",
    "text": "jq , please give me a data frame:\nBut wait what if we just want the properties?\n\nFirst let‚Äôs get their keys:\nAt the top level if we do ..\njq `keys` data/better_sample.geojson\n#[\n#  \"crs\",\n#  \"features\",\n#  \"type\"\n]\n.. we get the keys for the first array. We need to go in the features object to get properties and pass it to the keys function. We are a bit lazy and just ask for the first feature.\njq '.features[0].properties | keys' data/better_sample.geojson\n\n\nSecond make them into a csv\nHere we will need to buckle up a bit as our code is becoming quite a big line:\njq -r '(.features[0].properties | keys_unsorted), (.features[].properties | to_entries | map(.value))| @csv' data/better_sample.geojson &gt; data/sample.csv\n\n(.features[0].properties | keys_unsorted) here nothing new we added parentheses to enforce precedence. We are getting the header of our csv\n(.features[].properties | to_entries | map(.value)) :\n\nwe are starting from all our properties (not the first one)\npassing it to to_entries convert our object to multiple objects with ‚Äúkey‚Äù / ‚Äúvalue‚Äù (see margin)\nfinally, map(.value) gets all ‚Äúvalue‚Äù for every selected features\n\n\n\n\n{\n\"key\": \"state_abbr\",\n\"value\": \"VT\"\n},\n{\n\"key\": \"geoid_st\",\n\"value\": \"50\"\n},\n{\n\"key\": \"geoid_co\",\n\"value\": \"50005\"\n}\n\nFinally @csv convert to a csv and we redirect the output later in data/sample.csv\n\nWe have just explored the surface! jq can help to filter some specific features:\n\nevery geometries ‚Äúserved‚Äù in our file?\nthe first node in every geometries)?\netc!\n\njq is a generic tool for filtering json and lot of people are following the JSON spec in GeoJSON, so we can build on top of all their monumental work!"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Mapping & Data Analytics Blog @cori-risi",
    "section": "",
    "text": "The Center on Rural Innovation (CORI) is a 501(c)(3) nonprofit organization that partners with rural leaders across industries, across sectors and across the country to build tech economies that support scalable entrepreneurship and lead to more tech jobs in rural America.\nThese repositories are maintained by the Mapping and Data Analytics (MDA) team at CORI/RISI. Our team provides data, analytics and visualizations to support rural participation in the digital economy through scalable entrepreneurship and tech job growth in rural America. We aim to provide a better understanding of the forces and trends affecting rural America as we help communities chart a path to opportunity and prosperity through the tech economy.\nWe strive towards serving as the primary center of excellence advancing sustainable, economic opportunity and equity in rural America. We do this by providing expert spatial and statistical analysis, modernized visualization and tool development, credible technical subject matter expertise, and transparent documentation.\nFollow our work by reading our blog and reviewing the following list of past projects:\n\n\n\n\n\nBroadband - Broadband Equity Access and Deployment (BEAD) tool - Climate Risk Mapping\n\n\nResearch - Rural Aperture Project (RWJF) - Defining rural America - Who lives in rural America? Part 1 Part 2 - The equity of economic opportunity in rural America\n\n\n\n\nRural Innovation Network - Ascendium reports and data viz - Economic Development (ERC) tool\n\n\nRural Innovation Initiative - Tech Economy Diagnostic (TED)  (i.e., community assessment ‚Üí ERC tool)\n\n\n\n\nTech Entrepreneurship  - Feasibility studies - Tech Talent Tracker ‚Üí ERC tool\n\n\nAdditional work - Economic Development Administration (EDA) reports - Economic impact analysis - Multistate Workforce Analysis - example - Who Is Missing Analysis\n\n\n\nLearn more about the MDA approach to Knowledge here: Research, mapping, and data analytics"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Recent Posts",
    "section": "",
    "text": "From elephant to duck!\n\n\n\n\n\n\n\n\n\n\n\nJul 14, 2024\n\n\nOlivier Leroy, John Hall\n\n\n\n\n\n\n\n\n\n\n\n\nThe top 10 micropolitan areas for raising venture capital\n\n\n\n\n\n\n\n\n\n\n\nJul 3, 2024\n\n\nBrittany Kainen\n\n\n\n\n\n\n\n\n\n\n\n\nUsing SEC Form D to estimate venture capital\n\n\n\n\n\n\n\n\n\n\n\nJul 1, 2024\n\n\nBrittany Kainen\n\n\n\n\n\n\n\n\n\n\n\n\nMDA‚Äôs URISA-2023 presentation\n\n\n\n\n\n\n\n\n\n\n\nJun 20, 2024\n\n\nOlivier Leroy, Drew Rosebush\n\n\n\n\n\n\n\n\n\n\n\n\nSix tips for mapping rural data\n\n\n\n\n\n\n\n\n\n\n\nMay 24, 2024\n\n\nCamden Blatchly\n\n\n\n\n\n\n\n\n\n\n\n\nAwesome jq and GeoJSON\n\n\n\n\n\n\n\n\n\n\n\nMar 10, 2024\n\n\nOlivier Leroy\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/02_mapping_rural_tips/index.html",
    "href": "posts/02_mapping_rural_tips/index.html",
    "title": "Six tips for mapping rural data",
    "section": "",
    "text": "Mapping rural data is hard! Between sparse populations, inaccurate data, and the challenge of defining what even counts as rural, creating accurate and meaningful maps can be a minefield. In this blog post, I‚Äôll cover six tips for mapping rural data that will prepare you to confidently tackle your next rural-centric mapping project"
  },
  {
    "objectID": "posts/02_mapping_rural_tips/index.html#footnotes",
    "href": "posts/02_mapping_rural_tips/index.html#footnotes",
    "title": "Six tips for mapping rural data",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSee Openshaw, 1983: https://quantile.info/wp-content/uploads/2014/09/38-maup-openshaw.pdf‚Ü©Ô∏é"
  },
  {
    "objectID": "posts/04_formd_intro/index.html",
    "href": "posts/04_formd_intro/index.html",
    "title": "Using SEC Form D to estimate venture capital",
    "section": "",
    "text": "The ability of private companies to raise capital serves as a crucial indicator of entrepreneurial activity. The Security and Exchange Commission‚Äôs Form D is a publicly available dataset published quarterly that allows researchers to explore the landscape of venture capital investment.\nThe Securities Act of 1933 established the laws governing the sale of securities, including registration with the SEC and mandatory reporting of information that may be pertinent to the public‚Äôs investment decisions. Private companies wishing to raise capital from accredited investors may still do so under the exemption, ‚ÄúRegulation D.‚Äù\n\nHow Form D works\nRegulation D allows private companies to conduct fundraising rounds without registering with the SEC or regularly submitting information that is required for publicly traded companies. This exemption is the primary mechanism for early-stage ventures to access funding.\nWhen a company raises capital under Regulation D, they must file a Form D, which includes basic information about the company and the fundraising round. This data allows analysts to better understand who is raising venture capital and how much is invested.\nHowever, Form D data is often messy and riddled with human errors. Here are some tips on accessing and cleaning Form D data.\n\n\nCleaning up Form D data\nData going back to Q1 2008 can be downloaded directly from the SEC website. For a more streamlined process, we recommend accessing data in R using the dform package developed by Matt Rogers (download package from matthewjrogers/dform). This allows users to load data by quarter from 2014 to present.\nIf you download the Form D files directly through the SEC and sum the ‚ÄúTOTALAMOUNTSOLD‚Äù column the total amount of capital raised through Regulation D in 2022 would be approximately $10.4 trillion, which dramatically overestimates the actual amount of venture capital raised that year. Ernst & Young reported total U.S. venture capital raised in 2022 at $209.4 billion, Statista places it at $241 billion, and Dealroom at $235 billion.\nThis discrepancy is partly due to duplicate entries. The dform package takes a first pass at removing duplicates, reducing the total amount raised in 2022 to $4.9 trilion. This figure still overestimates the amount of venture capital raised by U.S. businesses in 2022. Therefore, once the data is accessed through dform, additional cleaning steps are necessary before the data can provide a realistic picture of the venture landscape.\nFirst, eliminate companies headquartered outside of the U.S. Removing these entries brings the estimate from $4.9 trillion down to $3.7 trillion.\nNext, retain only the latest amendment within a funding round. Companies may file amendments for various reasons. They may need to notify the SEC of additional capital raised within a single fundraising effort or for something as small as correcting a spelling error in a previous filing.\nBecause ‚ÄúTOTALAMOUNTSOLD‚Äù is cumulative for a fundraising round, simply summing this column would double-count funds already accounted for in other entries. In order to count these dollars once and attribute the most up-to-date total to the round, we recommend keeping only the latest entry for each funding round. This brings the total down to about $3.67 trillion.\nFinally, remove investment funds. Investment vehicles raising capital on the private market are also required to file a Form D. To distinguish these entities from startups or companies raising operational funds, we recommend separating them from the filings made by traditional businesses. We identify filings made by investment vehicles in the following ways:\n\nThe industry is reported as ‚ÄúPooled Investment Fund.‚Äù\nThe field ‚ÄúISPOOLEDINVESTMENTFUNDTYPE‚Äù is flagged as ‚ÄúTRUE.‚Äù This means the purpose of this fundraising round was for a pooled investment fund.\nThe entity name contains the word ‚ÄúFUND.‚Äù This indicates that the entity is actually an investment fund.\nThe entity name contains the word ‚ÄúHOLDING.‚Äù This indicates that the entity is actually a holding company.\n\nThis brings the final estimate for the total amount of venture funding raised by U.S. companies in 2022 down to about $233B.\nWhile other measures may further refine estimates based on Form D data, using the dform package and following these steps results in a final estimate consistent with other figures for 2022."
  },
  {
    "objectID": "presentations.html",
    "href": "presentations.html",
    "title": "MDA Presentations",
    "section": "",
    "text": "Beyond Raw Data\n\n\nStreamlining Broadband Insights with cori.data.fcc\n\n\n\n\n\n\n\n\nOct 20, 2024\n\n\nOlivier Leroy\n\n\n\n\n\n\n\n\n\n\n\n\nData Innovation\n\n\nAccelerating Broadband Analysis with cori.data.fcc\n\n\n\n\n\n\n\n\nOct 20, 2024\n\n\nOlivier Leroy\n\n\n\n\n\n\n\n\n\n\n\n\n[TITLE TBD]\n\n\ncori.data.fcc:: an example of data as code\n\n\n\n\n\n\n\n\nOct 20, 2024\n\n\nOlivier Leroy\n\n\n\n\n\n\n\n\n\n\n\n\nExtending Broadband to Underserved Areas\n\n\nHow rural areas are overrepresented in unserved areas and underestimated in statistics\n\n\n\n\n\n\n\n\nOct 18, 2023\n\n\nOlivier Leroy & Drew Rosebush\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/06_pg_duckdb/index.html",
    "href": "posts/06_pg_duckdb/index.html",
    "title": "From elephant to duck!",
    "section": "",
    "text": "There are a lot of conversations ‚Äî understandably ‚Äî on the use of Apache Parquet, Apache Arrow and DuckDB.\nThose three open source technologies and the amount of resources that a personal laptop has now have lowered the need of using a classic RDBMS for out-of-memory-tasks for data science works, and in some cases maybe the need of using a distributed computing framework like Spark.\nLet‚Äôs see an example of how they can be used to convert a table in a PostgresSQL database to a parquet file:"
  },
  {
    "objectID": "posts/06_pg_duckdb/index.html#libraries-and-data-optional-needed",
    "href": "posts/06_pg_duckdb/index.html#libraries-and-data-optional-needed",
    "title": "From elephant to duck!",
    "section": "Libraries and data (optional) needed",
    "text": "Libraries and data (optional) needed\n\nlibrary(duckdb)\nlibrary(dplyr, warn.conflicts = FALSE)\nlibrary(dbplyr, warn.conflicts = FALSE)\n\nWe will use FCC NBM raw data with December 2023‚Äôs release. You can learn more about on FCC website.\nThe table we will be converting has a size of 102 GB (without indexes), has 888,176,676 rows and 12 columns and it is the results of importing around 440 CSVs."
  },
  {
    "objectID": "posts/06_pg_duckdb/index.html#getting-your-credentials",
    "href": "posts/06_pg_duckdb/index.html#getting-your-credentials",
    "title": "From elephant to duck!",
    "section": "Getting your credentials",
    "text": "Getting your credentials\nSince this exercise is all about converting data that is currently stored in PostgreSQL (using R), the first step in connecting to your PG database server is getting your credentials. We are assuming here that you have a .pgpass file located in your home directory (~/.pgpass).\nThe code below will assume that you have this ~/.pgpass set and that it contains a one-line connection string.\n\nget_cred &lt;- function(path_pgpass) {\n  pgpass &lt;- readLines(path_pgpass)\n  cred &lt;- unlist(strsplit(pgpass, \":\"))\n  names(cred) &lt;- c(\"host\", \"port\", \"db\", \"user\", \"pwd\")\n  return(cred)\n}\n\ncred &lt;- get_cred(\"~/.pgpass\")"
  },
  {
    "objectID": "posts/06_pg_duckdb/index.html#use-duckdb-magic-to-convert-it",
    "href": "posts/06_pg_duckdb/index.html#use-duckdb-magic-to-convert-it",
    "title": "From elephant to duck!",
    "section": "Use DuckDB magic to convert it!",
    "text": "Use DuckDB magic to convert it!\nWell, the magic is a four-step steps process:\n\nConnect to DuckDB\nGet DuckDB‚Äôs postgres extension\nConnect to your DB (with the credential we have set)\nUse DuckDB COPY specifying where and how you want it to be partitioned\n\nThis will be wrapped in one function:\n\n# yes I am terrible at naming\nfrom_elephant_to_duck &lt;- function(table_name, path_for_parquet, part1, part2) {\n  # 1. Connect to duckDB\n  con &lt;- DBI::dbConnect(duckdb())\n  DBI::dbExecute(con,\n                 sprintf(\"SET temp_directory ='%s';\", tempdir()))\n  # cleaning up after the function\n  on.exit(DBI::dbDisconnect(con), add = TRUE)\n  \n  # 2. install and load PG extension\n  DBI::dbExecute(con, \"INSTALL postgres\")\n  DBI::dbExecute(con, \"LOAD postgres\")\n\n  # 3. Connect, \"attach\" to your PG server\n  attach_string &lt;- sprintf(\n    \"ATTACH 'dbname=%s user=%s password=%s host=%s' AS db (TYPE POSTGRES, READ_ONLY)\",\n    cred[\"db\"],\n    cred[\"user\"],\n    cred[\"pwd\"],\n    cred[\"host\"]\n  )\n  DBI::dbExecute(con, attach_string)\n\n  # 4. Copy to a parquet\n  copy_string &lt;- sprintf(\"COPY \n    (SELECT * \n      FROM db.%s)\n    TO '%s' (FORMAT 'parquet', PARTITION_BY(%s, %s))\", \n    table_name, \n    path_for_parquet, \n    part1, part2)\n  DBI::dbExecute(con, copy_string)\n\n  return(invisible(path_for_parquet))\n}\n# not an improvement on this function will be to take cred has an argument\n\n\nPartitioning\nDeciding how to partition a parquet is both a data and business decisions. In this case, state_abbr and technology are good tradeoffs in terms of the overall size of each parquet file and the fast performance of common filtering and grouping operations on this data."
  },
  {
    "objectID": "posts/06_pg_duckdb/index.html#lets-do-it-and-do-some-quick-comparisons",
    "href": "posts/06_pg_duckdb/index.html#lets-do-it-and-do-some-quick-comparisons",
    "title": "From elephant to duck!",
    "section": "Let‚Äôs do it and do some quick comparisons",
    "text": "Let‚Äôs do it and do some quick comparisons\n\nstart &lt;- Sys.time()\nfrom_elephant_to_duck(\"staging.dec23\", \"dec23\", \"state_abbr\", \"technology\")\nend &lt;- Sys.time()\nend - start\n# Time difference of 58.92108 mins\n\nOn a relatively new MacBook with a wifi-internet-speed connection (probably the limiting factor here) it took a little less than an hour to run from_elephant_to_duck.\nWe can also compare our 102 GB to the size of parquet files (ofc. PG offer additional perks!):\n\ndu -sh dec23/\n# 14 G\n\nFinally, just for the pleasure, let‚Äôs run a quick query:\n\nstart &lt;- Sys.time()\ncon &lt;- DBI::dbConnect(duckdb::duckdb(), shutdown = TRUE, dbdir = tempdir())\n\nreading_string &lt;-\n  sprintf(\"read_parquet('%s/*/*/*.parquet', hive_partitioning = true)\",\n          \"dec23\")\nfcc &lt;- dplyr::tbl(con, reading_string)\n\n# check number of row\nfcc |&gt; \n  summarize(tot_rows = count(location_id)) |&gt; \n  collect()\n\n# A tibble: 1 √ó 1\n#    tot_rows\n#       &lt;dbl&gt;\n# 1 888176676\n\n# let's start one a bit \nstart &lt;- Sys.time()\n# this will count every location_id by state_abbr and frn\n# that have low_latency\nstart &lt;- Sys.time()\nq1 &lt;- fcc |&gt;\n  filter(low_latency == TRUE) |&gt; \n  summarize(\n    count_location =  n_distinct(location_id),\n    .by = c(state_abbr, frn)\n  )\n\nrez_q1 &lt;- collect(q1)\nend - start\n# Time difference of 4.262549 mins\n\nDBI::dbDisconnect(con)\n\nImpressive, isn‚Äôt it? We will probably dig a bit deeper on those new technologies in future blog posts, so check back soon!"
  }
]