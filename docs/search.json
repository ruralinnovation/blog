[
  {
<<<<<<< HEAD
<<<<<<< HEAD
    "objectID": "index.html",
    "href": "index.html",
    "title": "Recent Posts",
    "section": "",
    "text": "The reclassification of rural counties and what it means for rural America\n\n\n\n\n\n\n\n\n\n\n\nApr 28, 2025\n\n\nCamden Blatchly\n\n\n\n\n\n\n\n\n\n\n\n\nHow we work with Form D filings\n\n\n\n\n\n\n\n\n\n\n\nApr 18, 2025\n\n\nCamden Blatchly\n\n\n\n\n\n\n\n\n\n\n\n\nRecapping our favorite visualizations of 2024\n\n\n\n\n\n\n\n\n\n\n\nMar 19, 2025\n\n\nCamden Blatchly\n\n\n\n\n\n\n\n\n\n\n\n\nDemocratizing analytics on FCC’s (big) data\n\n\nAccessing data about access to broadband\n\n\n\n\n\n\n\n\nFeb 12, 2025\n\n\nJohn Hall, Olivier Leroy\n\n\n\n\n\n\n\n\n\n\n\n\n3 cool uses of the cori.data.fcc package\n\n\n\n\n\nA quick primer on accessing, analyzing, and mapping FCC data using the cori.data.fcc package\n\n\n\n\n\nNov 11, 2024\n\n\nCamden Blatchly\n\n\n\n\n\n\n\n\n\n\n\n\nFrom elephant to duck!\n\n\n\n\n\n\n\n\n\n\n\nJul 14, 2024\n\n\nOlivier Leroy, John Hall\n\n\n\n\n\n\n\n\n\n\n\n\nThe top 10 micropolitan areas for raising venture capital\n\n\n\n\n\n\n\n\n\n\n\nJul 3, 2024\n\n\nBrittany Kainen\n\n\n\n\n\n\n\n\n\n\n\n\nUsing SEC Form D to estimate venture capital\n\n\n\n\n\n\n\n\n\n\n\nJul 1, 2024\n\n\nBrittany Kainen\n\n\n\n\n\n\n\n\n\n\n\n\nMDA’s URISA-2023 presentation\n\n\n\n\n\n\n\n\n\n\n\nJun 20, 2024\n\n\nOlivier Leroy, Drew Rosebush\n\n\n\n\n\n\n\n\n\n\n\n\nSix tips for mapping rural data\n\n\n\n\n\n\n\n\n\n\n\nMay 24, 2024\n\n\nCamden Blatchly\n\n\n\n\n\n\n\n\n\n\n\n\nAwesome jq and GeoJSON\n\n\n\n\n\n\n\n\n\n\n\nMar 10, 2024\n\n\nOlivier Leroy\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/15_cleaning_formd/index.html",
    "href": "posts/15_cleaning_formd/index.html",
    "title": "How we work with Form D filings",
    "section": "",
    "text": "We access raw Form D filings using the dform package. There are two datasets: issuers and offerings. The issuers dataset describes entities which are filing an offering, while the offerings dataset describes the terms of the offerings.\n\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\nformd_obj &lt;- dForm$new()\nformd_obj$load_data(years = c(2010:2023), use_cache = FALSE, remove_duplicates = FALSE)\nissuers &lt;- formd_obj$issuers\nofferings &lt;- formd_obj$offerings\n\n\nAssociating issuers with counties\nFirst, to clean entity and city names in the issuers dataset, we remove unnecessary whitespace and standardize common naming conventions (e.g., normalize L.P. to LP). Next, we associate each issuer with a county. When submitting a Form D filing, issuers must list an address. To convert from the address to a county, we take the following steps:\n\nWe begin by loading a zip code to county crosswalk that is produced by the Department of Housing and Urban Development. Because zip codes change over time, we use 2021 and 2014 versions of this crosswalk.\n\nThe simplest translation occurs when a zip code is associated with a single county. This is the most common scenario and is the case for about 70% of zip codes. When an issuer’s address is in a zip code associated with a single county, then we assign that county to the issuer.\n\nWhen an issuer’s zip code spans multiple counties, we assign the issuer to the county where more of the business addresses in the zip code are located, a field provided as part of the crosswalk. If those values are the same or not available, we assign the issuer to the county where more of the total (residential and business) addresses are located.\n\nAfter these two steps, we have assigned counties to the vast majority of issuers. For the remaining issuers, we use the Census geocoder to associate their address with a county. If an issuer is not matched with a county after this geocoding step, it is not used in our analysis. At the time of this writing, less than 500 issuers were unmatched after geocoding (out of a dataset of more than 500,000 issuers).\n\n\n\nAddressing filing discrepancies\n\n\nIssuers must also list a precise year of incorporation when filing. Because the yearofinc_value_entered field may be blank for some of an entity’s submissions, we group by the cik (the unique ID given by the SEC to entities) and the name of the entity, and then take the earliest year entered. If an entity is yet to be formed or is older than five years , the yearofinc_value_entered field may be NA. In these cases, we take the value in the yearofinc_timespan_choice field, which will be either ‘yetToBeFormed,’ ‘withinFiveYears,’ or ‘overFiveYears’\nformd_obj &lt;- dForm\\(new()\nformd_obj\\)load_data(years = c(2010:2023), use_cache = FALSE, remove_duplicates = FALSE)\nissuers &lt;- formd_obj\\(issuers\nofferings &lt;- formd_obj\\)offerings\n```\n\nAssociating issuers with counties\nFirst, to clean entity and city names in the issuers dataset, we remove unnecessary whitespace and standardize common naming conventions (e.g., normalize L.P. to LP). Next, we associate each issuer with a county. When submitting a Form D filing, issuers must list an address. To convert from the address to a county, we take the following steps:\n\nWe begin by loading a zip code to county crosswalk that is produced by the Department of Housing and Urban Development. Because zip codes change over time, we use 2021 and 2014 versions of this crosswalk.\n\nThe simplest translation occurs when a zip code is associated with a single county. This is the most common scenario and is the case for about 70% of zip codes. When an issuer’s address is in a zip code associated with a single county, then we assign that county to the issuer.\n\nWhen an issuer’s zip code spans multiple counties, we assign the issuer to the county where more of the business addresses in the zip code are located, a field provided as part of the crosswalk. If those values are the same or not available, we assign the issuer to the county where more of the total (residential and business) addresses are located.\n\nAfter these two steps, we have assigned counties to the vast majority of issuers. For the remaining issuers, we use the Census geocoder to associate their address with a county. If an issuer is not matched with a county after this geocoding step, it is not used in our analysis. At the time of this writing, less than 500 issuers were unmatched after geocoding (out of a dataset of more than 500,000 issuers).\n\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD Issuers must also list a precise year of incorporation when filing. Because the yearofinc_value_entered field may be blank for some of an entity’s submissions, we group by the cik (the unique ID given by the SEC to entities) and the name of the entity, and then take the smallest year entered. If an entity is yet to be formed or is older than five years , the yearofinc_value_entered field may be NA. In these cases, we take the value in the yearofinc_timespan_choice field, which will be either ‘yetToBeFormed,’ ‘withinFiveYears,’ or ‘overFiveYears’ &gt;&gt;&gt;&gt;&gt;&gt;&gt; 6efdad2 (added Form D blog post) ======= ### Addressing filing discrepancies\nIssuers must also list a precise year of incorporation when filing. Because the yearofinc_value_entered field may be blank for some of an entity’s submissions, we group by the cik (the unique ID given by the SEC to entities) and the name of the entity, and then take the earliest year entered. If an entity is yet to be formed or is older than five years , the yearofinc_value_entered field may be NA. In these cases, we take the value in the yearofinc_timespan_choice field, which will be either ‘yetToBeFormed,’ ‘withinFiveYears,’ or ‘overFiveYears’ &gt;&gt;&gt;&gt;&gt;&gt;&gt; 4b1c880 (incorporated Drew’s edits and rerendered)\nIssuers sometimes choose to change their industry association between submissions. To address these discrepancies, we collapse all industries for an entity into a single comma separated string (e.g., “Retailing, Restaurants”).\nAfter these steps, we are ready to join the issuers and offerings datasets. We join by accessionnumber (a unique ID number assigned by the SEC to each submission), year, and quarter and filter to submissions submitted by the primary issuer only (using the is_primaryissuer_flag field).\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD ### Identifying funding rounds and calculating investment totals\n======= &gt;&gt;&gt;&gt;&gt;&gt;&gt; 6efdad2 (added Form D blog post) ======= ### Identifying funding rounds and calculating investment totals\n\n\n\n\n\n\n\n4b1c880 (incorporated Drew’s edits and rerendered) The field “totalamountsold” is the basis for much of our Form D analysis. This field reports the cumulative amount of money raised by a company for a given fundraising effort (which may involve multiple offerings). Because this field is cumulative, we must identify the incremental difference in the amount raised between one offering and the last offering within a given fundraising effort. Failure to do this will artificially inflate the amount of funding raised in later periods. For example, if Company A raises $50k in 2016, their 2016 filing will report $50k as the total amount sold. But if they continue fundraising efforts and accrue an extra $20k in 2017, the 2017 filing will report $70k as the total amount sold, resulting in an inflated value of $50k for the 2017 filing year.\n\n\n\n\n\n\n\nThe steps to correct the dollar amount sold from each company for each fundraising effort are as follows:\n1. Create a business ID\nThe first 10 digits of the accession number (the unique ID given to offerings) is typically the CIK code (the unique ID given to entities), but not always. When the first 10 digits of the accession number differ from the CIK code, it suggests that there is a difference between that entity and an entity where the CIK code and accession number prefix match. Therefore, we use a combination between the CIK code and accession number prefix to identify offerings from the same business entity.\n2. Create a funding round ID and sort filings within the round.\nOur goal is to identify entries belonging to unique fundraising efforts for each company. To accomplish this aim, for each business ID, we assign a funding round ID to each group of filings that have the same values for the following fields:\n\nsale_date (the date the sale of securities was initiated).\n\nisequitytype (a true/false field indicating if the filing was the result of equity fundraising).\n\nisdebttype (a true/false field indicating if the filing was the result of debt financing).\n\nispooledinvestmentfundtype (a true/false field indicating if the filing was the result of raising capital or an investment fund).\n\nisbusinesscombinationtrans (a true/false field indicating if the filing was the result of M&A activity).\n\nOnce a business ID’s unique fundraising efforts have been identified, we determine the order in which each offering was filed using the accession number, which includes digits describing the year and the ordering of filing. After sorting the offerings, we can calculate the incremental amounts raised. The data is then separated into two separate tables (businesses and funds) based upon whether the security includes Pooled Investment Fund interests.\nNow the data is ready for analysis or visualization! Take a look at our private funding map to get a feel for how the data can be used. &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\n======= &gt;&gt;&gt;&gt;&gt;&gt;&gt; 6efdad2 (added Form D blog post)"
=======
=======
    "objectID": "posts/10_cori_data_fcc_overview/index.html",
    "href": "posts/10_cori_data_fcc_overview/index.html",
    "title": "3 cool uses of the cori.data.fcc package",
    "section": "",
    "text": "Here at the Center on Rural Innovation, we spend a lot of time thinking about broadband data. We’ve created detailed interactive maps of broadband service, produced research on the economic impacts of broadband on rural areas, and helped states and regions develop more equitable and effective broadband strategies. Now, we’re excited to share cori.data.fcc, an R package which makes Federal Communication Commission (FCC) broadband data releases more accessible than ever before.\nIn this blog post, I’ll cover three ways you can make use of our package to better understand broadband access and gaps."
  },
  {
    "objectID": "posts/10_cori_data_fcc_overview/index.html#view-broadband-service-in-your-area",
    "href": "posts/10_cori_data_fcc_overview/index.html#view-broadband-service-in-your-area",
    "title": "3 cool uses of the cori.data.fcc package",
    "section": "1. View broadband service in your area",
    "text": "1. View broadband service in your area\ncori.data.fcc makes it easy to quickly pull data on broadband service for your area. In particular, using the get_nbm_bl function, you can access a CORI-opinionated version of the National Broadband Map’s latest release at the Census block level for any U.S. county.\nIn the example below, I pull NBM data for the “Northeast Kingdom” of Vermont, a region consisting of Caledonia, Essex, and Orleans counties, and then bind them together.\n\ncaledonia_co_nbm &lt;- get_nbm_bl(geoid_co = \"50005\")\nessex_co_nbm &lt;- get_nbm_bl(geoid_co = \"50009\")\norleans_co_nbm &lt;- get_nbm_bl(geoid_co = \"50019\")\n\nnek_nbm &lt;- bind_rows(\n  caledonia_co_nbm,\n  essex_co_nbm,\n  orleans_co_nbm\n)\n\nHere’s what the data looks like:\n\nglimpse(nek_nbm)\n\nRows: 4,363\nColumns: 21\n$ geoid_bl                                &lt;chr&gt; \"500059570001000\", \"5000595700…\n$ geoid_st                                &lt;chr&gt; \"50\", \"50\", \"50\", \"50\", \"50\", …\n$ geoid_co                                &lt;chr&gt; \"50005\", \"50005\", \"50005\", \"50…\n$ cnt_total_locations                     &lt;int&gt; 1, 4, 5, 64, 3, 25, NA, 2, NA,…\n$ cnt_bead_locations                      &lt;int&gt; 0, 4, 4, 51, 3, 23, NA, 2, NA,…\n$ cnt_copper_locations                    &lt;int&gt; 0, 4, 2, 18, 3, 18, NA, 1, NA,…\n$ cnt_cable_locations                     &lt;int&gt; 0, 0, 0, 0, 0, 0, NA, 0, NA, 0…\n$ cnt_fiber_locations                     &lt;int&gt; 0, 0, 0, 0, 0, 0, NA, 0, NA, 0…\n$ cnt_other_locations                     &lt;int&gt; 0, 0, 0, 0, 0, 0, NA, 0, NA, 0…\n$ cnt_unlicensed_fixed_wireless_locations &lt;int&gt; 0, 0, 0, 0, 0, 0, NA, 0, NA, 0…\n$ cnt_licensed_fixed_wireless_locations   &lt;int&gt; 0, 2, 3, 46, 1, 14, NA, 2, NA,…\n$ cnt_LBR_fixed_wireless_locations        &lt;int&gt; 0, 0, 0, 1, 0, 2, NA, 0, NA, 0…\n$ cnt_terrestrial_locations               &lt;int&gt; 0, 4, 4, 51, 3, 23, NA, 2, NA,…\n$ cnt_25_3                                &lt;int&gt; 0, 1, 2, 40, 1, 5, NA, 0, NA, …\n$ cnt_100_20                              &lt;int&gt; 0, 0, 0, 0, 0, 0, NA, 0, NA, 0…\n$ cnt_100_100                             &lt;int&gt; 0, 0, 0, 0, 0, 0, NA, 0, NA, 0…\n$ cnt_distcint_frn                        &lt;int&gt; NA, 3, 2, 4, 2, 4, NA, 2, NA, …\n$ array_frn                               &lt;list&gt; &lt;NULL&gt;, &lt;\"0003645843\", \"00069…\n$ combo_frn                               &lt;dbl&gt; NA, 3.040635e+18, 8.391679e+18…\n$ release                                 &lt;date&gt; 2024-06-01, 2024-06-01, 2024-…\n$ state_abbr                              &lt;chr&gt; \"VT\", \"VT\", \"VT\", \"VT\", \"VT\", …\n\n\n\n\n\n\n\n\nTip\n\n\n\nIf you are curious what those columns mean, you can use get_fcc_dictionary(\"nbm_block\")\n\n\nNext, we can pull spatial data using the tigris package to help us visualize the NBM data.\n\n# Load all Vermont Census blocks\nvt_blocks &lt;- tigris::blocks(\"VT\", progress_bar = FALSE)\n\n# Load the Place boundary for the town of St. Johnsbury, VT\nvt_places &lt;- tigris::places(state = \"VT\", progress_bar = FALSE)\nstj_vt &lt;- vt_places %&gt;% filter(GEOID == \"5062125\")\n\nWe’re going to take a look at broadband service in the town of St. Johnsbury, VT - one of the main towns in the region. To do so, we can filter to blocks that intersect with St. Johnsbury’s place boundary and then combine this data with NBM data to calculate the percent of locations in each block in St. Johnsbury that have 100/20 Mbps service, the FCC service benchmark for high speed broadband.\n\nstj_vt_blocks &lt;- vt_blocks %&gt;%\n  filter(lengths(st_intersects(., stj_vt)) &gt; 0)\n\nstj_vt_bb_blocks &lt;- inner_join(\n    stj_vt_blocks,\n    nek_nbm,\n    by = c(\"GEOID20\" = \"geoid_bl\")\n  ) %&gt;%\n  mutate(\n    pct_100_20 = cnt_100_20 / cnt_total_locations\n  )\n\nNow that we’ve prepared our data, we can map it using ggplot to get a sense of the spatial trends of broadband access in St. Johnsbury.\n\nbbox &lt;- st_bbox(stj_vt_bb_blocks) %&gt;%\n      fit_bbox_to_aspect_ratio(target_aspect_ratio = 2)\n\nfig &lt;- ggplot(data = stj_vt_bb_blocks) +\n  base_map(\n    bbox,\n    increase_zoom = 3,\n    basemap = 'voyager'\n  ) +\n  geom_sf(aes(fill = pct_100_20), color = \"dimgray\", linewidth = .1, alpha = 0.9) +\n  scale_fill_cori(\n    discrete = FALSE,\n    palette = \"ctg2pu\",\n    labels = scales::label_percent(),\n    reverse = T\n  ) +\n  coord_sf(\n    expand = TRUE, \n    xlim = c(bbox['xmin'], bbox['xmax']), \n    ylim = c(bbox['ymin'], bbox['ymax'])\n  ) +\n  theme_cori_map() +\n  theme(\n    legend.key.width = unit(50, \"pt\"),\n  ) + \n  labs(\n    title = \"Broadband service in St. Johnsbury, VT\",\n    subtitle = \"Percent of locations with access to 100/20 Mbps service by census block\",\n    caption = \"Data source: 2023 FCC National Broadband Map\\nMap source: © OpenStreetMap contributors © CARTO\"\n  )\n\nsave_plot(fig, here(\"images/st_j_bb_service.png\"), chart_height = 8)\n\n\nWe can also easily plot broadband service data for the entire Northeast Kingdom.\n\n# Get Census block BB data for the Northeast Kingdom\nnek_bb_blocks &lt;- inner_join(\n    vt_blocks,\n    nek_nbm,\n    by = c(\"GEOID20\" = \"geoid_bl\")\n  ) %&gt;%\n  mutate(\n    pct_100_20 = cnt_100_20 / cnt_total_locations,\n    pct_fiber = cnt_fiber_locations / cnt_total_locations\n  )\n\n# Get major NEK Place centroids for map labeling\nvt_places_centroids &lt;- vt_places %&gt;%\n  st_as_sf() %&gt;%\n  st_centroid() %&gt;%\n   filter(lengths(st_intersects(., nek_bb_blocks)) &gt; 0)\n\n\nbbox &lt;- st_bbox(nek_bb_blocks) %&gt;%\n      fit_bbox_to_aspect_ratio(target_aspect_ratio = 2)\n\nfig &lt;- ggplot(data = nek_bb_blocks) +\n  base_map(\n    bbox,\n    increase_zoom = 3,\n    basemap = 'voyager'\n  ) +\n  geom_sf(aes(fill = pct_100_20), color = \"dimgray\", linewidth = 0.1, alpha = 0.9) +\n  scale_fill_cori(\n    discrete = FALSE,\n    palette = \"ctg2pu\",\n    labels = scales::label_percent(),\n    reverse = T\n  ) +\n  geom_sf_label(data = vt_places_centroids, \n                aes(label = NAME), size = 2, color = \"black\", family = \"Lato\", fontface = \"bold\") +  \n  coord_sf(\n    expand = TRUE, \n    xlim = c(bbox['xmin'], bbox['xmax']), \n    ylim = c(bbox['ymin'], bbox['ymax'])\n  ) +\n  theme_cori_map() +\n  theme(\n    legend.key.width = unit(50, \"pt\"),\n  ) + \n  labs(\n    title = \"Broadband service in the Northeast Kingdom\",\n    subtitle = \"Percent of locations with access to 100/20 Mbps service by census block\",\n    caption = \"Data source: 2023 FCC National Broadband Map\\nMap source: © OpenStreetMap contributors © CARTO\",\n    x = NULL,\n    y = NULL\n  )\n\nsave_plot(fig, here(\"images/nek_bb_service.png\"), chart_height = 8)\n\n\nBroadband access can also be analyzed by technology, including fiber, cable, and fixed wireless. This example map focuses on fiber access in the region.\n\nfig &lt;- ggplot(data = nek_bb_blocks) +\n  base_map(\n    bbox,\n    increase_zoom = 3,\n    basemap = 'voyager'\n  ) +\n  geom_sf(aes(fill = pct_fiber), color = \"dimgray\", linewidth = 0.1, alpha = 0.6) +\n  scale_fill_cori(\n    discrete = FALSE,\n    palette = \"ctg2pu\",\n    labels = scales::label_percent(),\n    reverse = T\n  ) +\n  geom_sf_label(data = vt_places_centroids, \n                aes(label = NAME), size = 2, color = \"black\", family = \"Lato\", fontface = \"bold\") +  \n  coord_sf(\n    expand = TRUE, \n    xlim = c(bbox['xmin'], bbox['xmax']), \n    ylim = c(bbox['ymin'], bbox['ymax'])\n  ) +\n  theme_cori_map() +\n  theme(\n    legend.key.width = unit(50, \"pt\"),\n  ) + \n  labs(\n    title = \"Fiber access in the Northeast Kingdom\",\n    subtitle = \"Percent of locations with access to fiber by census block\",\n    caption = \"Data source: 2023 FCC National Broadband Map\\nMap source: © OpenStreetMap contributors © CARTO\",\n    x = NULL,\n    y = NULL\n  )\n\nsave_plot(fig, here(\"images/nek_fiber_service.png\"), chart_height = 8)\n\n\nFiber service is pretty rare! Only a handful of towns have access.\nNext, let’s generate some summary statistics to see what percent of locations in the region have fiber access.\n\n# Calculate share of locations with access to fiber\nnek_locations_total &lt;- nek_bb_blocks %&gt;% \n  pull(cnt_total_locations) %&gt;%\n  sum(na.rm = T)\n\nnek_locations_fiber &lt;- nek_bb_blocks %&gt;%\n  pull(cnt_fiber_locations) %&gt;%\n  sum(na.rm = T)\n\nnek_locations_fiber / nek_locations_total\n\nTurns out only 11.5% locations have fiber access in the Northeast Kingdom."
  },
  {
    "objectID": "posts/10_cori_data_fcc_overview/index.html#view-internet-service-provider-isp-footprints",
    "href": "posts/10_cori_data_fcc_overview/index.html#view-internet-service-provider-isp-footprints",
    "title": "3 cool uses of the cori.data.fcc package",
    "section": "2. View Internet Service Provider (ISP) footprints",
    "text": "2. View Internet Service Provider (ISP) footprints\ncori.data.fcc can also be used to better understand ISP presence in an area. Let’s explore how by first pulling Form 477 data for the state of Vermont.\n\n# Pulling all Form 477 for the state of Vermont\nvt_477 &lt;- get_f477(\"VT\", frn = \"all\")\n\nIn this example, I’m interested in seeing the footprint for NEK Broadband, a community non-profit bringing high-speed broadband to the Northeast Kingdom.\nEach ISP has a unique FRN in the Form 477 data. To view, NEK Broadband data. we can filter using this unique FRN.\n\nnek_bb_frn &lt;- \"0031871197\" # This number can be found using cori.data.fcc::fcc_provider\n\nnek_service &lt;- vt_477  %&gt;%\n  filter(FRN == nek_bb_frn) %&gt;%\n  mutate(\n    Date = as.character(Date)\n  )\n\n# We could also have filtered using the frn argument: \n# nek_477 &lt;- get_f477(\"VT\", frn = \"0031871197\") \n\nHere’s what the Form 477 data looks like for NEK Broadband:\n\nglimpse(nek_service)\n\nRows: 49\nColumns: 15\n$ Provider_Id        &lt;chr&gt; \"82841\", \"82841\", \"82841\", \"82841\", \"82841\", \"82841…\n$ FRN                &lt;chr&gt; \"0031871197\", \"0031871197\", \"0031871197\", \"00318711…\n$ ProviderName       &lt;chr&gt; \"NEK Community Broadband\", \"NEK Community Broadband…\n$ DBAName            &lt;chr&gt; \"NEK Broadband\", \"NEK Broadband\", \"NEK Broadband\", …\n$ HoldingCompanyName &lt;chr&gt; \"NEK Broadband\", \"NEK Broadband\", \"NEK Broadband\", …\n$ HocoNum            &lt;chr&gt; \"450083\", \"450083\", \"450083\", \"450083\", \"450083\", \"…\n$ HocoFinal          &lt;chr&gt; \"NEK Community Broadband\", \"NEK Community Broadband…\n$ StateAbbr          &lt;chr&gt; \"VT\", \"VT\", \"VT\", \"VT\", \"VT\", \"VT\", \"VT\", \"VT\", \"VT…\n$ BlockCode          &lt;chr&gt; \"500059579001016\", \"500099505002004\", \"500099505003…\n$ TechCode           &lt;chr&gt; \"50\", \"50\", \"50\", \"50\", \"50\", \"50\", \"50\", \"50\", \"50…\n$ Consumer           &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRU…\n$ MaxAdDown          &lt;int&gt; 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 2…\n$ MaxAdUp            &lt;int&gt; 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 2…\n$ Business           &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRU…\n$ Date               &lt;chr&gt; \"2021-12-01\", \"2021-12-01\", \"2021-12-01\", \"2021-12-…\n\n\n\n\n\n\n\n\nTip\n\n\n\nUse get_fcc_dictionary(\"f477\") to get a description!\n\n\nTo map the data, we can once again join in with Census blocks from TIGRIS.\n\nnek_service_blocks &lt;- left_join(\n    nek_service,\n    vt_blocks,\n    by = c(\"BlockCode\" = \"GEOID20\")\n  ) %&gt;%\n  left_join(\n    .,\n    nek_nbm,\n    by = c(\"BlockCode\" = \"geoid_bl\")\n  ) %&gt;%\n  mutate(\n    pct_100_20 = cnt_100_20 / cnt_total_locations,\n    pct_fiber = cnt_fiber_locations / cnt_total_locations\n  ) %&gt;%\n  sf::st_as_sf()\n\n\nfig &lt;- ggplot(data = nek_service_blocks) +\n  base_map(\n    st_bbox(nek_service_blocks),\n    increase_zoom = 3,\n    basemap = 'voyager'\n  ) +\n  geom_sf(fill = \"black\", color = \"black\", linewidth = 0, alpha = .2) +\n  theme_cori_map() +\n  labs(\n    title = \"NEK Broadband service footprint\",\n    subtitle = \"By Census block\",\n    x = NULL,\n    y = NULL,\n    caption = \"Data source: 2021 FCC Form 477\\nMap source: © OpenStreetMap contributors © CARTO\",\n  )\n\nsave_plot(fig, here(\"images/nek_broadband_footprint.png\"), chart_height = 8.25)\n\n\nLet’s dig deeper and see what service levels NEK Broadband reports that they provide.\n\nfig &lt;- ggplot(data = nek_service_blocks) +\n  base_map(\n    st_bbox(nek_service_blocks),\n    increase_zoom = 3,\n    basemap = 'voyager'\n  ) +\n  geom_sf(aes(fill = pct_fiber), color = \"black\", linewidth = 0, alpha = .7) +\n  scale_fill_cori(\n    discrete = FALSE,\n    palette = \"ctg2pu\",\n    labels = scales::label_percent(),\n    reverse = TRUE\n  ) +\n  theme_cori_map() +\n  theme(\n    legend.key.width = unit(40, \"pt\")\n  ) +\n  labs(\n    title = \"NEK Broadband fiber service\",\n    subtitle = \"By Census block\",\n    x = NULL,\n    y = NULL,\n    caption = \"Data source: 2021 FCC Form 477\\nMap source: © OpenStreetMap contributors © CARTO\",\n  )\n\nsave_plot(fig, here(\"images/nek_broadband_fiber_service.png\"), chart_height = 9)"
  },
  {
    "objectID": "posts/10_cori_data_fcc_overview/index.html#compare-service-over-time",
    "href": "posts/10_cori_data_fcc_overview/index.html#compare-service-over-time",
    "title": "3 cool uses of the cori.data.fcc package",
    "section": "3. Compare service over time",
    "text": "3. Compare service over time\nFinally, we can use cori.data.fcc to see how reported broadband service levels vary over time.\nTo do so, we will use the get_county_nbm_raw function to load data for Caledonia County, VT from the 2022 and 2023 December NBM releases.\n\n# See what NBM releases are available\navailable_releases &lt;- get_nbm_release()\n\ncaledonia_2023 &lt;- get_county_nbm_raw(\"50005\", frn = \"all\", release = \"2023-12-01\") %&gt;%\n  mutate(year = 2023)\ncaledonia_2022 &lt;- get_county_nbm_raw(\"50005\", frn = \"all\", release = \"2022-12-01\") %&gt;%\n  mutate(year = 2022)\n\ncaledonia_combined &lt;- bind_rows(\n  caledonia_2022,\n  caledonia_2023\n)\n\nThe raw county data reports service levels for every broadband serviceable location. To create block totals, we will need to do some aggregation calculations.\n\n# Calculate the percent of locations with at least 100/20 Mbps service\ncaledonia_chg &lt;- caledonia_combined %&gt;%\n  mutate(\n    has_100_20_service = ifelse(\n      max_advertised_download_speed &gt;= 100 &\n        max_advertised_upload_speed &gt;= 20,\n      1,\n      0\n    )) %&gt;%\n  mutate(\n    valid_100_20_location = ifelse(has_100_20_service == 1, location_id, NA) \n  ) %&gt;%\n  # Filter out satellite coverage which overstates service levels\n  dplyr::filter(!technology %in% c(\"61\", \"60\")) %&gt;%\n  group_by(geoid_bl, year) %&gt;%\n  summarise(\n    # number of locations that have 100/20 service\n    count_100_20 = n_distinct(valid_100_20_location, na.rm = TRUE),\n    # number of location \n    count_total = n_distinct(location_id),\n    # number of services\n    n_services = n()\n  ) %&gt;%\n  mutate(\n    pct_100_20 = count_100_20 / count_total\n  ) %&gt;%\n  select(geoid_bl, count_100_20, count_total, n_services, pct_100_20, year)\n\n# Combine with tigris spatial data to get our data ready for mapping\ncaledonia_blocks &lt;- tigris::blocks(\"50\", county = \"005\")\n\nchrt_dta &lt;- left_join(\n    caledonia_blocks,\n    caledonia_chg,\n    by = c(\"GEOID20\" = \"geoid_bl\")\n  ) %&gt;%\n  filter(!is.na(year))\n\nNow our data is ready to map!\n\nfig &lt;- ggplot(data = chrt_dta) +\n  base_map(\n    st_bbox(chrt_dta),\n    increase_zoom = 3,\n    basemap = 'voyager'\n  ) +\n  geom_sf(aes(fill = pct_100_20), color = \"black\", linewidth = .05, alpha = .7) +\n  scale_fill_cori(\n    discrete = FALSE,\n    palette = \"ctg2pu\",\n    labels = scales::label_percent(),\n    reverse = TRUE\n  ) +\n  theme_cori_map() +\n  theme(\n    legend.key.width = unit(40, \"pt\"),\n    strip.text = element_text(face = \"bold\", size = 12)\n  ) +\n  labs(\n    title = \"Caledonia County broaband service over time\",\n    subtitle = \"Percent of locations with 100/20 Mbps broadband service, by Census block\",\n    x = NULL,\n    y = NULL,\n    caption = \"Data source: 2022 and 2023 FCC NBM\\nMap source: © OpenStreetMap contributors © CARTO\",\n  ) +\n  facet_wrap(~year, ncol = 2)\n\nsave_plot(fig, here(\"images/caledonia_broadband_100_20_service.png\"), chart_height = 8.5)\n\n\nThere’s a lot more to discover in the package, so I highly recommend you check out the reference documentation and give it a try yourself."
  },
  {
>>>>>>> 79a1402 (produced image files)
    "objectID": "posts/14_nonmetro_to_metro/analysis.html",
    "href": "posts/14_nonmetro_to_metro/analysis.html",
    "title": "analysis",
    "section": "",
    "text": "library(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyr)\nlibrary(here)\n\nhere() starts at /Users/camdenblatchly/Desktop/code/blog\n\nlibrary(readr)\nlibrary(coriverse)\n\nCoriverse has cori.utils and cori.db attached\n\nlibrary(ggplot2)\nlibrary(cori.charts)\n\nload_fonts()\n\ni_am(\"posts/14_nonmetro_to_metro/analysis.qmd\")\n\nhere() starts at /Users/camdenblatchly/Desktop/code/blog\nrucc_1974 &lt;- ruraldefinitions::rucc_1974 %&gt;%\n  mutate(rural_def = as.character(rural_def))\nrucc_1983 &lt;- ruraldefinitions::rucc_1983 %&gt;%\n  mutate(rural_def = as.character(rural_def))\nrucc_1993 &lt;- ruraldefinitions::rucc_1993 %&gt;%\n  mutate(rural_def = as.character(rural_def))\nrucc_2003 &lt;- ruraldefinitions::rucc_2003 %&gt;%\n  mutate(rural_def = as.character(rural_def))\nrucc_2013 &lt;- ruraldefinitions::rucc_2013 %&gt;%\n  mutate(rural_def = as.character(rural_def))\nrucc_2023 &lt;- ruraldefinitions::rucc_2023 %&gt;%\n  mutate(rural_def = as.character(rural_def))\nrucc_all &lt;- bind_rows(\n    rucc_1974,\n    rucc_1983,\n    rucc_1993,\n    rucc_2003,\n    rucc_2013,\n    rucc_2023\n  ) %&gt;%\n  left_join(\n    .,\n    cori.utils::county_state_crosswalk,\n    by = c(\"geoid\" = \"geoid_co\")\n  ) %&gt;%\n  select(-rural_def) %&gt;%\n  pivot_wider(\n    names_from = \"year\",\n    names_prefix = \"rucc_\",\n    values_from = \"is_rural\"\n  ) %&gt;%\n  mutate(\n    rural_to_nonrural = ifelse(\n      rucc_1974 == \"Rural\" & rucc_1983 == \"Nonrural\",\n      1983,\n      ifelse(\n        rucc_1974 == \"Rural\" & rucc_1993 == \"Nonrural\",\n        1993,\n        ifelse(\n          rucc_1974 == \"Rural\" & rucc_2003 == \"Nonrural\",\n          2003,\n          ifelse(\n            rucc_1974 == \"Rural\" & rucc_2013 == \"Nonrural\",\n            2013,\n            ifelse(\n              rucc_1974 == \"Rural\" & rucc_2023 == \"Nonrural\",\n              2023,\n              NA\n            )\n          )\n        )\n      )\n    ),\n    nonrural_to_rural = ifelse(\n      rucc_1974 == \"Nonrural\" & rucc_1983 == \"Rural\",\n      1983,\n      ifelse(\n        rucc_1974 == \"Nonrural\" & rucc_1993 == \"Rural\",\n        1993,\n        ifelse(\n          rucc_1974 == \"Nonrural\" & rucc_2003 == \"Rural\",\n          2003,\n          ifelse(\n            rucc_1974 == \"Nonrural\" & rucc_2013 == \"Rural\",\n            2013,\n            ifelse(\n              rucc_1974 == \"Nonrural\" & rucc_2023 == \"Rural\",\n              2023,\n              NA\n            )\n          )\n        )\n      )\n    )\n  )\n  \nreadr::write_csv(rucc_all, here(\"posts/14_nonmetro_to_metro/data/rucc_over_time.csv\"))\ncon &lt;- connect_to_db(\"proj_erc\")\nerc_dta &lt;- read_db(con, \"erc_data_tidy\")\nDBI::dbDisconnect(con)"
  },
  {
    "objectID": "posts/14_nonmetro_to_metro/analysis.html#data-for-nonmetro-to-metro-2013-2023",
    "href": "posts/14_nonmetro_to_metro/analysis.html#data-for-nonmetro-to-metro-2013-2023",
    "title": "analysis",
    "section": "Data for Nonmetro to Metro (2013-2023)",
    "text": "Data for Nonmetro to Metro (2013-2023)\n\nnonmetro_to_metro_geoids &lt;- rucc_all %&gt;%\n  filter(rural_to_nonrural == 2023) %&gt;%\n  pull(geoid)\n\nanalysis_dta &lt;- erc_dta %&gt;%\n  filter(metric %in% c(\n    \"Median age\",\n    \"Number of establishments\",\n    \"Population\",\n    \"Quality of life\",\n    \"Educational attainment\",\n    \"Employment\",\n    \"Tech employment\",\n    \"Share of employment by sector\",\n    \"Broadband adoption\"\n  ))\n\nsum_metrics &lt;- c(\n  \"Population\", \n  \"Number of establishments\",\n  \"Employment\"\n)\n\nweight_metrics &lt;- c(\n  \"Broadband adoption\",\n  \"Tech employment\",\n  \"Share of employment by sector\",\n  \"Educational attainment\"\n)\n\nrucc_nonmetro_2023 &lt;- rucc_2023 %&gt;%\n  filter(is_rural == \"Rural\") %&gt;%\n  pull(geoid) %&gt;% unique()\n\nnonmetro_to_metro_summary &lt;- analysis_dta %&gt;%\n  mutate(\n    category = ifelse(\n      geoid %in% nonmetro_to_metro_geoids,\n      \"Newly nonrural\",\n      ifelse(\n        geoid %in% rucc_nonmetro_2023,\n        \"Rural\",\n        \"All other nonrural\"\n      )\n    )\n  ) %&gt;%\n  mutate(\n    weighted_value = agg_var * value\n  ) %&gt;%\n  group_by(category, year, variable, metric) %&gt;%\n  summarise(\n    count = n_distinct(geoid),\n    weighted_value_sum = sum(weighted_value, na.rm = TRUE),\n    total_value = sum(value, na.rm = T),\n    agg_var = sum(agg_var, na.rm = T),\n    value = mean(value, na.rm = TRUE)\n  ) %&gt;%\n  ungroup() %&gt;%\n  mutate(\n    value = ifelse(\n      metric %in% sum_metrics,\n      total_value,\n      ifelse(\n        metric %in% weight_metrics,\n        weighted_value_sum / agg_var,\n        value\n      )\n    )\n  )\n\n`summarise()` has grouped output by 'category', 'year', 'variable'. You can\noverride using the `.groups` argument.\n\n\n\nchart_vars &lt;- c(\n  \"Tradable services\",\n  \"establishments\",\n  \"pct_emp_in_computer_math_occupations\",\n  \"population\",\n  \"broadband_adoption\",\n  \"share_ba_or_higher\",\n  \"employment\",\n  \"median_age\"\n)\n\nchrt_dta &lt;- nonmetro_to_metro_summary %&gt;%\n  filter(variable %in% chart_vars) %&gt;%\n  filter(year %in% c(2017, 2018, 2022, 2023)) %&gt;%\n  select(category, year, variable, value) %&gt;% \n  pivot_wider(\n    names_from = \"year\",\n    names_prefix = \"est_\",\n    values_from = \"value\"\n  ) %&gt;%\n  mutate(\n    pct_chg_2023 = (est_2023 - est_2018) / est_2018,\n    pct_chg_2022 = (est_2022 - est_2017) / est_2017\n  ) %&gt;%\n  select(category, variable, est_2022, est_2023, tidyr::starts_with(\"pct\")) %&gt;%\n  tidyr::pivot_longer(\n    cols = c(est_2023, est_2022, tidyr::starts_with(\"pct\"))\n  ) %&gt;%\n  filter(!is.na(value)) %&gt;%\n  filter(\n    !(name == \"pct_chg_2023\" & variable == \"pct_emp_in_computer_math_occupations\")\n  ) %&gt;%\n  filter(\n    !(name == \"pct_chg_2023\" & variable == \"share_ba_or_higher\")\n  ) %&gt;%\n  filter(!(name == \"est_2022\" & variable != \"Tradable services\")) %&gt;%\n  mutate(\n    variable_label = recode(variable,\n    \"employment\" = \"Percent change in employment (2017-2022)\",\n    \"establishments\" = \"Percent change in businesses (2017-2022)\",\n    \"population\" = \"Percent change in population (2017-2022)\",\n    \"pct_emp_in_computer_math_occupations\" = \"Share employed in tech (2023)\",\n    \"share_ba_or_higher\" = \"Share with a college degree (2023)\",\n    \"broadband_adoption\" = \"Share of households with a broadband subscription (2023)\",\n    \"median_age\" = \"Average median age (2023)\",\n    \"Tradable services\" = \"Share employed in tradable services (2022)\"\n    ),\n    category = factor(category, levels = c(\n        \"All other nonrural\",\n        \"Newly nonrural\",\n        \"Rural\"\n      )\n    )\n  )\n\n\nfig &lt;- chrt_dta %&gt;%\n  filter(variable %in% c(\"employment\", \"population\", \"establishments\")) %&gt;%\n  ggplot(aes(value, variable_label, fill = category)) +\n  geom_col(position = \"dodge\") +\n  # Add in data labels\n  geom_text(\n    aes(label = scales::percent(value, accuracy = .1)),\n    position = position_dodge2(width = 0.9, reverse = FALSE),\n    hjust = -.2,\n    family = \"Lato\",\n    fontface = \"bold\",\n    size = 5\n  ) +\n  scale_fill_manual(\n    values = c(\n      \"All other nonrural\" = cori_colors[[\"Dark Purple\"]],\n      \"Newly nonrural\" = \"#d0d2ce\",\n      \"Rural\" = cori_colors[[\"Emerald\"]] \n    ),\n    guide = guide_legend(reverse = TRUE)\n  ) +\n  scale_x_continuous(\n    labels = NULL,\n    expand = expansion(mult = c(0, .1))\n  ) +\n  labs(\n    title = \"Newly nonrural counties are growing quickly\",\n    subtitle = \"By 2023 metropolitan designation\",\n    x = NULL,\n    y = NULL,\n    caption = 'Source: Bureau of Economic Analysis\\nNote: \"Rural\" refers to the nonmetro definition which includes all nonmetro counties.'\n  ) +\n  theme_cori_horizontal_bars() +\n  theme(\n    axis.text.y = element_blank(),\n    strip.text = element_text(\n      hjust = -.01,\n      family = \"Lato\",\n      face = \"bold\",\n      size = 14\n    ),\n    legend.text = element_text(margin = margin(l = 4, r = 8))\n  ) +\n  facet_wrap(~variable_label, ncol = 1, scales = \"free\")\n\nsave_plot(fig, here(\"posts/14_nonmetro_to_metro/growth.png\"), chart_height = 8)\n\n\nfig &lt;- chrt_dta %&gt;%\n  filter(!variable %in% c(\"employment\", \"population\", \"establishments\", \"pct_emp_in_computer_math_occupations\", \"median_age\")) %&gt;%\n  ggplot(aes(value, variable_label, fill = category)) +\n  geom_col(position = \"dodge\") +\n  # Add in data labels\n  geom_text(\n    aes(label = ifelse(\n      variable != \"median_age\",\n      scales::percent(value, accuracy = .1), \n      scales::number(value, accuracy = .1)\n    )),\n    position = position_dodge2(width = 0.9, reverse = FALSE),\n    hjust = -.2,\n    family = \"Lato\",\n    fontface = \"bold\",\n    size = 5\n  ) +\n  scale_fill_manual(\n    values = c(\n      \"All other nonrural\" = cori_colors[[\"Dark Purple\"]],\n      \"Newly nonrural\" = \"#d0d2ce\",\n      \"Rural\" = cori_colors[[\"Emerald\"]] \n    ),\n    guide = guide_legend(reverse = TRUE)\n  ) +\n  scale_x_continuous(\n    labels = NULL,\n    expand = expansion(mult = c(0, .1))\n  ) +\n  labs(\n    title = \"Newly nonrural counties are better positioned in the modern\\neconomy than rural ones, but lag behind other nonrural counties\",\n    subtitle = \"By 2023 metropolitan designation\",\n    x = NULL,\n    y = NULL,\n    caption = 'Source: Bureau of Economic Analysis, American Community Survey 5-year estimates\\nNote: \"Rural\" refers to the nonmetro definition which includes all nonmetro counties.'\n  ) +\n  theme_cori_horizontal_bars() +\n  theme(\n    axis.text.y = element_blank(),\n    strip.text = element_text(\n      hjust = -.01,\n      family = \"Lato\",\n      face = \"bold\",\n      size = 14\n    ),\n    legend.text = element_text(margin = margin(l = 4, r = 8))\n  ) +\n  facet_wrap(~variable_label, ncol = 1, scales = \"free\")\n\nsave_plot(fig, here(\"posts/14_nonmetro_to_metro/modern_economy.png\"), chart_height = 8)"
<<<<<<< HEAD
>>>>>>> 33c6a8d (adding more to my nonmetro to metro analysis)
=======
  },
  {
    "objectID": "posts/15_cleaning_formd/index.html",
    "href": "posts/15_cleaning_formd/index.html",
    "title": "How we work with Form D filings",
    "section": "",
    "text": "We access raw Form D filings using the dform package. There are two datasets: issuers and offerings. The issuers dataset describes entities which are filing an offering, while the offerings dataset describes the terms of the offerings.\n\nformd_obj &lt;- dForm$new()\nformd_obj$load_data(years = c(2010:2023), use_cache = FALSE, remove_duplicates = FALSE)\nissuers &lt;- formd_obj$issuers\nofferings &lt;- formd_obj$offerings\n\n\nAssociating issuers with counties\nFirst, to clean entity and city names in the issuers dataset, we remove unnecessary whitespace and standardize common naming conventions (e.g., normalize L.P. to LP). Next, we associate each issuer with a county. When submitting a Form D filing, issuers must list an address. To convert from the address to a county, we take the following steps:\n\nWe begin by loading a zip code to county crosswalk that is produced by the Department of Housing and Urban Development. Because zip codes change over time, we use 2021 and 2014 versions of this crosswalk.\n\nThe simplest translation occurs when a zip code is associated with a single county. This is the most common scenario and is the case for about 70% of zip codes. When an issuer’s address is in a zip code associated with a single county, then we assign that county to the issuer.\n\nWhen an issuer’s zip code spans multiple counties, we assign the issuer to the county where more of the business addresses in the zip code are located, a field provided as part of the crosswalk. If those values are the same or not available, we assign the issuer to the county where more of the total (residential and business) addresses are located.\n\nAfter these two steps, we have assigned counties to the vast majority of issuers. For the remaining issuers, we use the Census geocoder to associate their address with a county. If an issuer is not matched with a county after this geocoding step, it is not used in our analysis. At the time of this writing, less than 500 issuers were unmatched after geocoding (out of a dataset of more than 500,000 issuers).\n\n\n\nAddressing filing discrepancies\nIssuers must also list a precise year of incorporation when filing. Because the yearofinc_value_entered field may be blank for some of an entity’s submissions, we group by the cik (the unique ID given by the SEC to entities) and the name of the entity, and then take the earliest year entered. If an entity is yet to be formed or is older than five years , the yearofinc_value_entered field may be NA. In these cases, we take the value in the yearofinc_timespan_choice field, which will be either ‘yetToBeFormed,’ ‘withinFiveYears,’ or ‘overFiveYears’\nIssuers sometimes choose to change their industry association between submissions. To address these discrepancies, we collapse all industries for an entity into a single comma separated string (e.g., “Retailing, Restaurants”).\nAfter these steps, we are ready to join the issuers and offerings datasets. We join by accessionnumber (a unique ID number assigned by the SEC to each submission), year, and quarter and filter to submissions submitted by the primary issuer only (using the is_primaryissuer_flag field).\n\n\nIdentifying funding rounds and calculating investment totals\nThe field “totalamountsold” is the basis for much of our Form D analysis. This field reports the cumulative amount of money raised by a company for a given fundraising effort (which may involve multiple offerings). Because this field is cumulative, we must identify the incremental difference in the amount raised between one offering and the last offering within a given fundraising effort. Failure to do this will artificially inflate the amount of funding raised in later periods. For example, if Company A raises $50k in 2016, their 2016 filing will report $50k as the total amount sold. But if they continue fundraising efforts and accrue an extra $20k in 2017, the 2017 filing will report $70k as the total amount sold, resulting in an inflated value of $50k for the 2017 filing year.\nThe steps to correct the dollar amount sold from each company for each fundraising effort are as follows:\n1. Create a business ID\nThe first 10 digits of the accession number (the unique ID given to offerings) is typically the CIK code (the unique ID given to entities), but not always. When the first 10 digits of the accession number differ from the CIK code, it suggests that there is a difference between that entity and an entity where the CIK code and accession number prefix match. Therefore, we use a combination between the CIK code and accession number prefix to identify offerings from the same business entity.\n2. Create a funding round ID and sort filings within the round.\nOur goal is to identify entries belonging to unique fundraising efforts for each company. To accomplish this aim, for each business ID, we assign a funding round ID to each group of filings that have the same values for the following fields:\n\nsale_date (the date the sale of securities was initiated).\n\nisequitytype (a true/false field indicating if the filing was the result of equity fundraising).\n\nisdebttype (a true/false field indicating if the filing was the result of debt financing).\n\nispooledinvestmentfundtype (a true/false field indicating if the filing was the result of raising capital or an investment fund).\n\nisbusinesscombinationtrans (a true/false field indicating if the filing was the result of M&A activity).\n\nOnce a business ID’s unique fundraising efforts have been identified, we determine the order in which each offering was filed using the accession number, which includes digits describing the year and the ordering of filing. After sorting the offerings, we can calculate the incremental amounts raised. The data is then separated into two separate tables (businesses and funds) based upon whether the security includes Pooled Investment Fund interests.\nNow the data is ready for analysis or visualization! Take a look at our private funding map to get a feel for how the data can be used."
  },
  {
    "objectID": "posts/12_fcc-data/index.html",
    "href": "posts/12_fcc-data/index.html",
    "title": "Democratizing analytics on FCC’s (big) data",
    "section": "",
    "text": "The FCC’s public release of the National Broadband Map should, in theory, allow broadband providers to maximize their access to the unprecedented availability of public and private investment funding, but utilizing this data continues to pose challenges for rural service providers.\nOne of our goals at the Center on Rural Innovation (CORI) is to support rural stakeholders with practical insights and applications that will empower them to bridge the digital divide and expand equitable access to the internet across underserved communities.\nIn this post, we aim to:"
  },
  {
    "objectID": "posts/12_fcc-data/index.html#the-challenge-and-the-opportunity",
    "href": "posts/12_fcc-data/index.html#the-challenge-and-the-opportunity",
    "title": "Democratizing analytics on FCC’s (big) data",
    "section": "The challenge and the opportunity",
    "text": "The challenge and the opportunity\nAt this time, reliable high-speed broadband access and widespread digital literacy are more critical than ever, yet vast areas of rural America remain underserved. This digital gap limits opportunities for education, healthcare, economic growth, and civic engagement in these regions. With billions of dollars in federal and state funding now available, the ability to analyze and interpret broadband data effectively is paramount. Providers need actionable insights to identify unserved and underserved areas, optimize funding applications, and plan infrastructure investments that meet local needs.\n\nWhy this matters now\nThe convergence of new funding opportunities and improved datasets represents a once-in-a-generation opportunity to close the digital divide. By leveraging accurate data and strategic planning, rural broadband providers can maximize their impact and secure funding to expand their services.\nInvestment in broadband, especially by small, locally-operated providers, can accelerate economic growth and prosperity in rural areas. Higher broadband utilization is associated with increased business growth rates, self-employment, per capita income, and GDP growth. Conversely, areas with low broadband utilization face economic stagnation and population decline.1\nPrivate capital investment, alongside government funding, can help small broadband providers deploy infrastructure. However, uneven investment can lead to rural-urban and rich-poor divides in internet quality, because internet service providers tend to “invest in the best technology in areas where there are competitive environments, and they will invest in the latest technology in wealthier areas”.2 To counter this tendency we need compelling data-driven narratives and objectives that enable communities to hold their local provider(s) accountable, even as they make critical planning decisions that will reverberate for decades.3\nAdditionally, in regards to the Broadband Equity Access and Deployment Program, the largest offering of federal assistance for broadband infrastructure deployment to-date,4 the NTIA guidelines prioritize fiber deployment due to its reliability and future-proof capabilities, followed by other communications technologies (i.e. fixed wireless and satellite).5 While the NTIA acknowledges the necessity of alternative technologies in high-cost areas, it has emphasized that fiber’s high data transmission capacity can handle current and future broadband demands, ensuring that networks can grow alongside digital demands. This means that knowing precisely where fiber is available (or planned) is an essential prerequisite for the prudent allocation of investment priorities that will result in a long-term, reliable and resilient broadband ecosystem.6"
  },
  {
    "objectID": "posts/12_fcc-data/index.html#the-available-data",
    "href": "posts/12_fcc-data/index.html#the-available-data",
    "title": "Democratizing analytics on FCC’s (big) data",
    "section": "The available data",
    "text": "The available data\nThe following explanation of the data sourced from the FCC is extracted from CORI’s FCC report, a work-in-progress exploratory data analysis produced by Olivier Leroy. Please visit the report for a deeper analysis of various aspects of this data.\nWe rely on two key datasets from the Federal Communications Commission (FCC):\n\nNational Broadband Map (NBM):\n\n\nProvides granular information on broadband service availability at specific locations, including details about service providers, technology types, and advertised speeds.\n\n\nBroadband Funding Map (BFM):\n\n\nOffers insights into federally funded broadband infrastructure projects, detailing program boundaries and project-level information.\n\nBoth datasets are publicly available under permissive licensing, making them invaluable tools for analyzing broadband coverage and funding opportunities. Licensing information can be found here and here, respectively.7\n\nWhat are these two datasets?\nOn March 23, 2020, the Broadband Deployment Accuracy and Technological Availability Act or Broadband DATA Act was enacted8. This led to the FCC’s creation of the National Broadband Map (NBM) in November 20229 and the Broadband Funding Map in May 202310 (documented in July 202311) as the primary methods of publicly releasing these datasets.\n\n\nIn the legislation and sometimes on FCC documents the process of collecting this data is called Broadband Data Collection (BDC).\n\nNational Broadband Map (NBM)\nThe NBM offers detailed broadband availability information:\n\nIdentifies providers and technologies at each location.\nClassifies locations as residential, business, or both.\nLocalizes data to census blocks or H3 hexagons.\n\nThis dataset is an abstraction of the “Fabric” locations data developed by CostQuest. The Fabric provides precise geolocation data for Broadband Serviceable Locations (BSLs), which are updated biannually (June and December) with interim updates every two weeks. The exact coordinates for each locations are only inclued in the Fabric dataset, so using the National Broadband Map data we can only link a record for a location to a Census Block (2020 vintage) or H3 hexagon.\n\n\n\n\n\n\nFigure 1: “What’s on the national broadband map” Source: https://www.fcc.gov/BroadbandData\n\n\n\nEvery location is characterized by:\n\nWho is providing those services (frn, provider_id, and brand_name)\nA description of each of the services (technology, max_advertised_download_speed, max_advertised_upload_speed, low_latency)\nWhether the location is characterised as residential, business or both\nWays to geographically locate it (state_abbr, block_geoid, h3_res8_id)\n\n\n\n\n\n\n\nTip\n\n\n\nA location (see What is a BSL?) can be covered by multiple Internet Services Provides (ISP) with potentially different services and technologies. Hence, it can be represented in the data by many “rows”.\n\n\n\n\nBroadband Funding Map (BFM)\nThe BFM provides information about “broadband infrastructure deployment projects funded by the Federal government throughout the United States”. The public data:\n\nCategorizes projects by program and geographic boundaries.\nHighlights funding from four federal agencies across 12 programs, including 1,853 projects as of May 2024.\nProvides a critical resource for identifying areas targeted for infrastructure investment.\n\nThe information is structured either at the scale of a specific project inside a program or for the whole program. Hence we have characteristics for each project, including their associated boundaries (territories covered) (see https://ruralinnovation.github.io/proj-fcc-report/fcc_funding.html).\n\n\n\nWhat is a Broadband Serviceable Location (BSL)?\nA Broadband Serviceable Location (BSL) is defined as a location in the U.S. where fixed broadband internet access service is available or can be installed. These include:\n\nResidential BSLs: Housing units or group quarters as defined by the U.S. Census Bureau.\nBusiness BSLs: Non-residential structures, such as government or nonprofit facilities, on properties without residential locations.\n\n\nA broadband serviceable location is defined as “a business or residential location in the United States at which fixed broadband Internet access service is, or can be, installed.” A residential BSL includes all residential structures, including structures that are (or contain) housing units or group quarters (as those terms are defined by the United States Census Bureau). A business BSL includes “all non-residential (business, government, non-profit, etc.) structures that are on property without residential locations and that would expect to demand Internet access service.” (source FCC12)\n\n\nGeographic coverage\n\nBroadband Availability Data: Covers all U.S. states, Puerto Rico, and U.S. territories.\nFunding Map Data: Varies by program, with coverage reflecting specific project boundaries.\n\n\n\n\nWhat is “Unserved” vs. “Underserved”?\nThe FCC defines broadband access levels as follows:\n\nServed: Locations with at least one service offering speeds of 100/20 or higher.\nUnderserved: Locations with speeds of at least 25/3 but below 100 Mbps download / 20 Mbps upload (100/20).\nUnserved: Locations with maximum advertised speeds below 25 Mbps download / 3 Mbps upload (25/3).\n\nServed, Unserved and Underseved are overlapping categories at the location level. They can be extended at the “area level”.\nThese definitions, rooted in the FCC’s Broadband Speed Benchmark, can be adapted by states to suit local conditions13."
  },
  {
    "objectID": "posts/12_fcc-data/index.html#tools-for-big-broadband-analytics",
    "href": "posts/12_fcc-data/index.html#tools-for-big-broadband-analytics",
    "title": "Democratizing analytics on FCC’s (big) data",
    "section": "Tools for big broadband analytics",
    "text": "Tools for big broadband analytics\nBeginning in 2023 and throughout 2024 we developed the following tools to support rural broadband providers and local policymakers:\n\ncori.data.fcc: R package that facilitates the discovery, analysis, retrieval and use of FCC public data releases.\n\nBecause the FCC publishes major releases of this data twice a year and minor updates at a nearly biweekly cadence, we developed cori.data.fcc to ease the process of provisioning our various applications with the latest broadband coverage data.\n\nCORI Data API: This backend was designed and implemented to provide an assortment of broadband service metrics and demographic data at multiple geographic levels (county, tract, block, etc.)\n\nBuilt with AWS Lambda and RDS (PostgreSQL)\nContinuously deploys from code commits using AWS CDK\nThis allowed us to build multiple frontend applications that incorporate a mix of backend data sources, including CORI Data API and Mapbox (styles and tile sets):\n\nRural Broadband Service Map: Visualizes broadband availability and funding data to identify gaps and opportunities.\nRural Broadband County Summary: Summarizes broadband availability and demographic data per county (by name or FIPS).\nBroadband Climate Risk Mitigation Tool: Assesses climate risks posed to broadband infrastructure in order to enhance resiliency.\n\n\n\nThese tools are vital for connecting rural areas, acting as a bridge to digital opportunities and effective investment of resources. Instead of just providing raw data, CORI’s resources turn complex information into clear insights, enabling deliberate, informed choices about where to direct funds and build infrastructure.\nHere’s how this suite of tools helps to improve broadband investment, expansion, and digital skills:\n\nSimplified Data Management: The cori.data.fcc package streamlines the process of accessing and utilizing the FCC’s frequently updated data, ensuring that users always have the most current information at their fingertips\nComprehensive Data Analysis: The CORI Data API delivers key broadband metrics and demographic information across different geographic areas, enabling a detailed understanding of local needs and opportunities\nTargeted Visualizations: The Rural Broadband Service Map offers a visual representation of broadband availability and funding, highlighting areas with service gaps and potential for growth.\nConcise Summaries: The Rural Broadband County Summary provides a snapshot of broadband and demographic data for each county, facilitating quick comparisons and informed decision-making.\nRisk Assessment: The Broadband Climate Risk Mitigation Tool evaluates potential climate-related threats to broadband infrastructure, promoting the development of more resilient networks.\n\nThe broadband tools offered by CORI highlight underserved areas, attracting focused infrastructure investment. By visualizing current broadband availability and funding, the maps identify gaps, guiding strategic expansion and making sure resources go where they’re most needed to promote fair access and close the digital gap. In this way we make accessible the data and insights needed to create persuasive funding requests. With broadband metrics and demographic details, applicants to BEAD and other public funding programs can build a strong case for investment, highlighting local needs and project potential.\nInternet service providers that avail themselves of these resources can create resilient networks that deliver reliable, high-speed internet by analyzing coverage and assessing climate risks. Strategic broadband investments, particularly by smaller, local providers, spark economic growth in rural areas. As previously mentioned, increased broadband use correlates with higher business growth, self-employment, income, and GDP. CORI tools empower these providers to make data-informed decisions about infrastructure deployment in collaboration with local communities. CORI’s resources support data-backed infrastructure planning, aligning investments with community needs.\nWhile focused on infrastructure, these tools also help to increase digital skills by expanding broadband in underserved areas. Reliable internet is essential for digital literacy, enabling multiple stakeholders, policymakers and residents alike, to develop skills and plan their participation in the digital world. Digital literacy leads to individual growth that boosts local economies which then attract new businesses. Ultimately, these tools help the rural communities and broadband providers that strategically and holistically invest in infrastructure, to encourage and enable digital inclusion.\nCopyright © 2025 Center On Rural Innovation\n\n\nFootnotes"
  },
  {
    "objectID": "posts/12_fcc-data/index.html#footnotes",
    "href": "posts/12_fcc-data/index.html#footnotes",
    "title": "Democratizing analytics on FCC’s (big) data",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWeinstein, A., Erouart, M., & Dewbury, A. (2024) Beyond Connectivity: The role of broadband in rural economic growth and resilience. Center on Rural Innovation. https://ruralinnovation.us/resources/reports/report-the-role-of-broadband-in-rural-economic-growth-and-resilience/↩︎\nPigeons are still (sometimes) faster than your internet https://www.washingtonpost.com/technology/2023/11/10/pigeons-are-faster-than-your-internet/↩︎\nCapital Beginning to Flow in Advance of BEAD Allocations - Inside Towers https://insidetowers.com/capital-beginning-to-flow-in-advance-of-bead-allocations/↩︎\nNotices of Funding Opportunity for the Broadband Equity Access and Deployment Program https://www.ntia.gov/funding-programs/internet-all/broadband-equity-access-and-deployment-bead-program/program-documentation/notice-funding-opportunity-broadband-equity-access-and-deployment-program↩︎\nFinal Guidance for BEAD Funding of Alternative Broadband Technology https://www.ntia.gov/blog/2025/final-guidance-bead-funding-alternative-broadband-technology↩︎\nA Deep Dive On the BEAD Alternative Technology Guidelines https://www.telecompetitor.com/a-deep-dive-on-the-bead-alternative-technology-guidelines/↩︎\nLicense and Attribution language from the FCC:   Broadband availability data from the BDC, and data from the U.S. Census Bureau that are presented on this site, are offered free and not subject to copyright restriction. Data and content created by government employees within the scope of their employment are not subject to domestic copyright protection under 17 U.S.C. § 105. See, e.g., U.S. Government Works.   While not required, when using in your own work content, data, documentation, code, and related materials from fcc.gov or broadbandmap.fcc.gov, we ask that you provide proper attribution of the data. Examples include:   Source data: FCC Broadband Funding Map  Map layer based on FCC BFM   CostQuest Associates, Inc. and its third-party licensors, as applicable, own all right, title, and interest, including all intellectual property rights, in and to the data for locations reflected in the Fabric (including the Location ID, latitude and longitude, address, unit count, and building type code for each location in the Fabric). CostQuest is granted certain rights to Fabric correction submissions for the purpose of correcting or otherwise modifying BDC Fabric data. Broadband service providers, governmental entities, and other third parties are able to license Fabric data, including any changes to Fabric data that have been made as a result of challenges, at no cost for purposes of their participation in the FCC’s Broadband Data Collection.↩︎\nBroadband Data and Mapping Background and Issues for the 117th Congress https://crsreports.congress.gov/product/pdf/r/r45962↩︎\nhttps://www.fcc.gov/news-events/notes/2022/11/18/new-broadband-maps-are-finally-here↩︎\nhttps://docs.fcc.gov/public/attachments/DA-23-410A1.pdf↩︎\nhttps://us-fcc.app.box.com/v/bfm-data-downloads-output↩︎\n“The Fabric data”↩︎\nPage 4 https://www.pewtrusts.org/-/media/assets/2023/06/un–and-underserved-definitions-ta-memo-pdf.pdf↩︎"
  },
  {
    "objectID": "posts/04_formd_intro/index.html",
    "href": "posts/04_formd_intro/index.html",
    "title": "Using SEC Form D to estimate venture capital",
    "section": "",
    "text": "The ability of private companies to raise capital serves as a crucial indicator of entrepreneurial activity. The Security and Exchange Commission’s Form D is a publicly available dataset published quarterly that allows researchers to explore the landscape of venture capital investment.\nThe Securities Act of 1933 established the laws governing the sale of securities, including registration with the SEC and mandatory reporting of information that may be pertinent to the public’s investment decisions. Private companies wishing to raise capital from accredited investors may still do so under the exemption, “Regulation D.”\n\nHow Form D works\nRegulation D allows private companies to conduct fundraising rounds without registering with the SEC or regularly submitting information that is required for publicly traded companies. This exemption is the primary mechanism for early-stage ventures to access funding.\nWhen a company raises capital under Regulation D, they must file a Form D, which includes basic information about the company and the fundraising round. This data allows analysts to better understand who is raising venture capital and how much is invested.\nHowever, Form D data is often messy and riddled with human errors. Here are some tips on accessing and cleaning Form D data.\n\n\nCleaning up Form D data\nData going back to Q1 2008 can be downloaded directly from the SEC website. For a more streamlined process, we recommend accessing data in R using the dform package developed by Matt Rogers (download package from matthewjrogers/dform). This allows users to load data by quarter from 2014 to present.\nIf you download the Form D files directly through the SEC and sum the “TOTALAMOUNTSOLD” column the total amount of capital raised through Regulation D in 2022 would be approximately $10.4 trillion, which dramatically overestimates the actual amount of venture capital raised that year. Ernst & Young reported total U.S. venture capital raised in 2022 at $209.4 billion, Statista places it at $241 billion, and Dealroom at $235 billion.\nThis discrepancy is partly due to duplicate entries. The dform package takes a first pass at removing duplicates, reducing the total amount raised in 2022 to $4.9 trilion. This figure still overestimates the amount of venture capital raised by U.S. businesses in 2022. Therefore, once the data is accessed through dform, additional cleaning steps are necessary before the data can provide a realistic picture of the venture landscape.\nFirst, eliminate companies headquartered outside of the U.S. Removing these entries brings the estimate from $4.9 trillion down to $3.7 trillion.\nNext, retain only the latest amendment within a funding round. Companies may file amendments for various reasons. They may need to notify the SEC of additional capital raised within a single fundraising effort or for something as small as correcting a spelling error in a previous filing.\nBecause “TOTALAMOUNTSOLD” is cumulative for a fundraising round, simply summing this column would double-count funds already accounted for in other entries. In order to count these dollars once and attribute the most up-to-date total to the round, we recommend keeping only the latest entry for each funding round. This brings the total down to about $3.67 trillion.\nFinally, remove investment funds. Investment vehicles raising capital on the private market are also required to file a Form D. To distinguish these entities from startups or companies raising operational funds, we recommend separating them from the filings made by traditional businesses. We identify filings made by investment vehicles in the following ways:\n\nThe industry is reported as “Pooled Investment Fund.”\nThe field “ISPOOLEDINVESTMENTFUNDTYPE” is flagged as “TRUE.” This means the purpose of this fundraising round was for a pooled investment fund.\nThe entity name contains the word “FUND.” This indicates that the entity is actually an investment fund.\nThe entity name contains the word “HOLDING.” This indicates that the entity is actually a holding company.\n\nThis brings the final estimate for the total amount of venture funding raised by U.S. companies in 2022 down to about $233B.\nWhile other measures may further refine estimates based on Form D data, using the dform package and following these steps results in a final estimate consistent with other figures for 2022."
  },
  {
    "objectID": "posts/02_mapping_rural_tips/index.html",
    "href": "posts/02_mapping_rural_tips/index.html",
    "title": "Six tips for mapping rural data",
    "section": "",
    "text": "Mapping rural data is hard! Between sparse populations, inaccurate data, and the challenge of defining what even counts as rural, creating accurate and meaningful maps can be a minefield. In this blog post, I’ll cover six tips for mapping rural data that will prepare you to confidently tackle your next rural-centric mapping project"
  },
  {
    "objectID": "posts/02_mapping_rural_tips/index.html#footnotes",
    "href": "posts/02_mapping_rural_tips/index.html#footnotes",
    "title": "Six tips for mapping rural data",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSee Openshaw, 1983: https://quantile.info/wp-content/uploads/2014/09/38-maup-openshaw.pdf↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Recent Posts",
    "section": "",
    "text": "The reclassification of rural counties and what it means for rural America\n\n\n\n\n\n\n\n\n\n\n\nApr 28, 2025\n\n\nCamden Blatchly\n\n\n\n\n\n\n\n\n\n\n\n\nHow we work with Form D filings\n\n\n\n\n\n\n\n\n\n\n\nApr 18, 2025\n\n\nCamden Blatchly\n\n\n\n\n\n\n\n\n\n\n\n\nRecapping our favorite visualizations of 2024\n\n\n\n\n\n\n\n\n\n\n\nMar 19, 2025\n\n\nCamden Blatchly\n\n\n\n\n\n\n\n\n\n\n\n\nDemocratizing analytics on FCC’s (big) data\n\n\nAccessing data about access to broadband\n\n\n\n\n\n\n\n\nFeb 12, 2025\n\n\nJohn Hall, Olivier Leroy\n\n\n\n\n\n\n\n\n\n\n\n\n3 cool uses of the cori.data.fcc package\n\n\n\n\n\nA quick primer on accessing, analyzing, and mapping FCC data using the cori.data.fcc package\n\n\n\n\n\nNov 11, 2024\n\n\nCamden Blatchly\n\n\n\n\n\n\n\n\n\n\n\n\nFrom elephant to duck!\n\n\n\n\n\n\n\n\n\n\n\nJul 14, 2024\n\n\nOlivier Leroy, John Hall\n\n\n\n\n\n\n\n\n\n\n\n\nThe top 10 micropolitan areas for raising venture capital\n\n\n\n\n\n\n\n\n\n\n\nJul 3, 2024\n\n\nBrittany Kainen\n\n\n\n\n\n\n\n\n\n\n\n\nUsing SEC Form D to estimate venture capital\n\n\n\n\n\n\n\n\n\n\n\nJul 1, 2024\n\n\nBrittany Kainen\n\n\n\n\n\n\n\n\n\n\n\n\nMDA’s URISA-2023 presentation\n\n\n\n\n\n\n\n\n\n\n\nJun 20, 2024\n\n\nOlivier Leroy, Drew Rosebush\n\n\n\n\n\n\n\n\n\n\n\n\nSix tips for mapping rural data\n\n\n\n\n\n\n\n\n\n\n\nMay 24, 2024\n\n\nCamden Blatchly\n\n\n\n\n\n\n\n\n\n\n\n\nAwesome jq and GeoJSON\n\n\n\n\n\n\n\n\n\n\n\nMar 10, 2024\n\n\nOlivier Leroy\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Mapping & Data Analytics Blog @cori-risi",
    "section": "",
    "text": "The Center on Rural Innovation (CORI) is a 501(c)(3) nonprofit organization that partners with rural leaders across industries, across sectors and across the country to build tech economies that support scalable entrepreneurship and lead to more tech jobs in rural America.\nThese repositories are maintained by the Mapping and Data Analytics (MDA) team at CORI/RISI. Our team provides data, analytics and visualizations to support rural participation in the digital economy through scalable entrepreneurship and tech job growth in rural America. We aim to provide a better understanding of the forces and trends affecting rural America as we help communities chart a path to opportunity and prosperity through the tech economy.\nWe strive towards serving as the primary center of excellence advancing sustainable, economic opportunity and equity in rural America. We do this by providing expert spatial and statistical analysis, modernized visualization and tool development, credible technical subject matter expertise, and transparent documentation.\nFollow our work by reading our blog and reviewing the following list of past projects:\n\n\n\n\n\nBroadband - Broadband Equity Access and Deployment (BEAD) tool - Climate Risk Mapping\n\n\nResearch - Rural Aperture Project (RWJF) - Defining rural America - Who lives in rural America? Part 1 Part 2 - The equity of economic opportunity in rural America\n\n\n\n\nRural Innovation Network - Ascendium reports and data viz - Economic Development (ERC) tool\n\n\nRural Innovation Initiative - Tech Economy Diagnostic (TED)  (i.e., community assessment → ERC tool)\n\n\n\n\nTech Entrepreneurship  - Feasibility studies - Tech Talent Tracker → ERC tool\n\n\nAdditional work - Economic Development Administration (EDA) reports - Economic impact analysis - Multistate Workforce Analysis - example - Who Is Missing Analysis\n\n\n\nLearn more about the MDA approach to Knowledge here: Research, mapping, and data analytics"
  },
  {
    "objectID": "posts/01_awesomejq/index.html",
    "href": "posts/01_awesomejq/index.html",
    "title": "Awesome jq and GeoJSON",
    "section": "",
    "text": "If you are manipulating a lot of GeoJSON features/objects and want a quick CLI tool to filter and slice them, you should give jq a try! Since there are not many tutorials that exist on using jq to manage objects in the GeoJSON family, we hope that these few tricks will help you on your learning journey.\nIn these examples, we are using a GeoJSON file of Vermont census blocks with attributes related to our work on broadband data. While it is not a deeply nested JSON, it is perfect to illustrate some common use cases.\nA quick check lets us know that it is 94 MB. Not “that” big but still decent.\nFirst, let’s see how many features it has. Here’s how we can approximate that:\nThis is a decent estimate, but we are counting some rows at the top and bottom of the file that are not features (try head -n 5 and tail on it if you are curious).\nWe can also use jq:\nThis is the correct number of blocks! How did that magic work? Let’s decompose our one-liner:"
  },
  {
    "objectID": "posts/01_awesomejq/index.html#jq-and-small-examples",
    "href": "posts/01_awesomejq/index.html#jq-and-small-examples",
    "title": "Awesome jq and GeoJSON",
    "section": "jq and small examples",
    "text": "jq and small examples\nIt is always a good idea to start experimenting with smaller data so let’s start there:\njq '.features[0:5]'  data/vt-bb.geojson &gt; data/not_perfect_sample.geojson\nHere we asked for the [0 to 5[ (yes: [inclusive:exclusive]) features (i.e. the first 5) and jq produces a valid JSON but if you inspect it you will see that we moved from GeoJSON to a JSON array.\njq '.' data/not_perfect_sample.geojson | head -n 4\n# [\n#   {\n#     \"type\": \"Feature\",\n#     \"properties\": {\n# to compare with :\njq '.' data/vt-bb.geojson | head -n 12/\n# { \n#   \"type\": \"FeatureCollection\",\n#   \"name\": \"sql_statement\",\n#   \"crs\": {\n#     \"type\": \"name\",\n#     \"properties\": {\n#       \"name\": \"urn:ogc:def:crs:EPSG::4269\"\n#     }\n#   },\n#   \"features\": [\n#     {\n#       \"type\": \"Feature\",\nWe used .features so jq returned the following value (here an array with all the features) but we lost type, name, and crs.\nYou probably have noticed that . is used to return all the input as output but by default jq will prettify the JSON.\nIf we want to keep them we will need to be slighly more verbose:\njq '{type: .type , crs: .crs ,features: .features[0:10]}' data/vt-bb.geojson &gt; data/better_sample.geojson \nHere we introduced {} allowing you to build a JSON object. We then “stick them” together and send them to a new JSON with a proper type and crs (grabbed from our original file)."
  },
  {
    "objectID": "posts/01_awesomejq/index.html#extracting-geometries",
    "href": "posts/01_awesomejq/index.html#extracting-geometries",
    "title": "Awesome jq and GeoJSON",
    "section": "Extracting geometries!",
    "text": "Extracting geometries!\nIf we just want the geometries of our census blocks:\njq '{type: .type , crs: .crs ,features: [.features[] | del(.properties)]}' better_sample.geojson &gt; sample_only_geom.geojson  \nHere we are streaming a filter on .features[] into a function that will delete all properties (del(.properties)) and this will be used as an array for features.\nWe will need to adjust that code a bit for data/vt-bb.geojson:\njq --compact-output  '{type: .type , crs: .crs ,features: [.features[] | del(.properties)]}'  data/vt-bb.geojson &gt; data/geom.geojson\n--compact-output will convert to a single line JSON (and saved space!). Now data/geom.geojson is 72MB."
  },
  {
    "objectID": "posts/01_awesomejq/index.html#jq-please-give-me-a-data-frame",
    "href": "posts/01_awesomejq/index.html#jq-please-give-me-a-data-frame",
    "title": "Awesome jq and GeoJSON",
    "section": "jq , please give me a data frame:",
    "text": "jq , please give me a data frame:\nBut wait what if we just want the properties?\n\nFirst let’s get their keys:\nAt the top level if we do ..\njq `keys` data/better_sample.geojson\n#[\n#  \"crs\",\n#  \"features\",\n#  \"type\"\n]\n.. we get the keys for the first array. We need to go in the features object to get properties and pass it to the keys function. We are a bit lazy and just ask for the first feature.\njq '.features[0].properties | keys' data/better_sample.geojson\n\n\nSecond make them into a csv\nHere we will need to buckle up a bit as our code is becoming quite a big line:\njq -r '(.features[0].properties | keys_unsorted), (.features[].properties | to_entries | map(.value))| @csv' data/better_sample.geojson &gt; data/sample.csv\n\n(.features[0].properties | keys_unsorted) here nothing new we added parentheses to enforce precedence. We are getting the header of our csv\n(.features[].properties | to_entries | map(.value)) :\n\nwe are starting from all our properties (not the first one)\npassing it to to_entries convert our object to multiple objects with “key” / “value” (see margin)\nfinally, map(.value) gets all “value” for every selected features\n\n\n\n\n{\n\"key\": \"state_abbr\",\n\"value\": \"VT\"\n},\n{\n\"key\": \"geoid_st\",\n\"value\": \"50\"\n},\n{\n\"key\": \"geoid_co\",\n\"value\": \"50005\"\n}\n\nFinally @csv convert to a csv and we redirect the output later in data/sample.csv\n\nWe have just explored the surface! jq can help to filter some specific features:\n\nevery geometries “served” in our file?\nthe first node in every geometries)?\netc!\n\njq is a generic tool for filtering json and lot of people are following the JSON spec in GeoJSON, so we can build on top of all their monumental work!"
  },
  {
    "objectID": "posts/03_urisa-2023/index.html",
    "href": "posts/03_urisa-2023/index.html",
    "title": "MDA’s URISA-2023 presentation",
    "section": "",
    "text": "The Urban and Regional Information Systems Association — better known as URISA — is the main association for professionals in the GIS and geospatial space.\nWe were fortunate enough to be selected to present a portion of our work on broadband infrastructure at URISA’s annual conference GIS-Pro-2023 last fall in Columbus, Ohio.\nOur presentation, “Rural areas are overrepresented in unserved areas and underestimated in statistics,” utilized FCC NBM data to demonstrate several points:\n\nThe new dataset (NBM) represents an improvement over the previous one (derived from F477).\nDespite the narrowing gap between rural and nonrural areas, significant disparities still exist.\nThe current BEAD definition of an “unserved area” is less suitable for rural areas than for urban areas.\n\nYou can dig more into our presentation HERE!"
  },
  {
    "objectID": "posts/05_micropolitan_formd/index.html",
    "href": "posts/05_micropolitan_formd/index.html",
    "title": "The top 10 micropolitan areas for raising venture capital",
    "section": "",
    "text": "Venture capital funding plays a pivotal role in bolstering a region’s economy by catalyzing innovation, fostering job creation, and attracting talent.\nVenture capital investment injects vital funding into promising businesses with growth potential, enabling them to scale rapidly. And it holds immense promise for revitalizing rural America’s economy by empowering local entrepreneurs with the resources needed to innovate and grow.\nThough rural areas have traditionally been overlooked by investors, many rural entrepreneurs have managed to access capital that is crucial to transforming their budding ideas into thriving businesses.\nTo explore the venture capital landscape in rural America, we can use the SEC’s Form D to identify the amount of funding received by private businesses in micropolitan areas. A micropolitan area, as defined by the U.S. Office of Management and Budget, is a region centered around a small urban cluster with a population between 10,000 and 50,000 people. These areas are smaller than metropolitan areas but still exhibit economic and social connections with nearby population centers, making micropolitans an ideal geography for observing venture capital dynamics in rural economies.\n\n\n\n\n\n\nHere are the micropolitan areas that raised the most venture capital in 2022:\n\n\nAnd here are the micropolitan areas that raised the most in venture capital funding per capita in 2022:\n\n\n\n\n\n\n\nMicro VC totals (click chart to enlarge)\n\n\n\n\n\n\n\nMicro VC chart (click chart to enlarge)\n\n\n\n\n\n\nSheridan, Heber, and Jackson achieved these outcomes through an abundance of venture capital activity, while the others are driven by a couple companies with very large deals in 2022.\nOf the 81 micropolitans that raised venture capital through Regulation D in 2022, the 10 that raised the most represent 84% of the $1.4 billion in funding that went to micropolitan areas.\n\nThe 10 micropolitans with the most funding per capita varied widely by population size. Grants, New Mexico, had the smallest population (11,620), while the population of Bozeman, Montana, (109,207) was much larger than the others on this list. Heber, Utah was the second-largest micropolitan area in the top 10 (68,075).\n\nEach of these micropolitan areas demonstrates that rural communities are ripe with entrepreneurial spirit and offer investors an abundance of opportunities.\nIf you’d like to dig deeper on the power of direct investment in rural startups, check out our seed fund, the CORI Innovation Fund, which has a growing portfolio of rural tech startups with high-growth potential. Or you can connect with our team directly to learn more!"
  },
  {
    "objectID": "posts/13_favorite_viz/index.html",
    "href": "posts/13_favorite_viz/index.html",
    "title": "Recapping our favorite visualizations of 2024",
    "section": "",
    "text": "From downtown placemaking to broadband planning and economic research, data-driven analysis has remained at the heart of CORI’s work this past year. To highlight the hard work that goes into analyzing and visualizing rural data, we’ve compiled our favorite charts, graphics, and interactive visualizations from 2024 below.\n\nMapping Affordable Connectivity Program enrollment\n\n\nThe Affordable Connectivity Program ended in June 2024, impacting 23 million households—many in rural areas—that relied on the program for reduced-cost or fully subsidized internet access. To illustrate the program’s reach and assess the effects of its discontinuation, we created, in collaboration with Rural LISC, an interactive map showing ACP utilization over time for U.S. zip codes. The map visualizes the steady rise in enrollment rates, demonstrating how, for most participants, the ACP was the difference between having access to the opportunities that connectivity offers and being left behind.\n\n\nVisualizing the role of broadband in rural economic growth\n\n\n\n\nFor our recent report on the impacts of broadband on rural economic growth, we visualized how higher broadband utilization (higher broadband adoption rates and a higher prevalence of small broadband service providers) improves the economic dynamism of rural areas. One key takeaway: rural counties with high broadband utilization see increases in the number of businesses, while similar counties without high broadband utilization see businesses decline.\n\n\nOpen data for rural placemaking\n\n\n\n\nTo better understand land use when developing innovation districts, we visualized OpenStreetMap and parcel tax data for the communities of Pine Bluff, AR, Selma, AL, and Rutland VT, helping residents easily compare community priorities with their current downtown structure.\n\n\nMapping broadband access and funding\n\n\nIn February 2024, we released the Rural Broadband Service Map—the most detailed map of broadband service and funding available. With data displayed at the Census block level, users can readily identify areas lacking broadband access and assess grant eligibility and strategy.\n\n\nCharting changes in rural voting patterns\n\n\nFollowing the 2024 election, we analyzed the recent divergence in rural and nonrural voting trends, visualizing how increasing polarization has manifested across the country - and in rural areas.\n\n\nSpatial trends in rural innovation funding\n\n\nBuild to Scale, the Economic Development Administration’s flagship grant program for technology-driven businesses, recently celebrated its 10th anniversary. To analyze spatial trends among grantees and identify rural communities with strong potential for successful applications, we developed a statistical model (and associated mapping tool) that leverages attributes of past winners to estimate the likelihood of a rural area receiving this prestigious grant.\n\n\nDisadvantaged rural communities charting a path to economic success\n\n\nIn our final installment of the Rural Aperture Project, we explored how rural communities that are most affected by systemic inequities can nonetheless chart a path towards economic success and well-being. Our data-driven analysis centered around a comparative study of 20 communities classified as Disadvantaged or Most Disadvantage according to the University of Michigan’s Index of Deep Disadvantage, visualizing the key factors that have contributed to their success despite systemic challenges."
  },
  {
    "objectID": "posts/14_nonmetro_to_metro/index.html",
    "href": "posts/14_nonmetro_to_metro/index.html",
    "title": "The reclassification of rural counties and what it means for rural America",
    "section": "",
    "text": "Why is rural America perceived as being perpetually in decline? In part, because superstar rural counties often grow into run-of-the-mill urban counties.\nWhat counts as “rural” is a moving target. Every ten years, the Office of Management and Budget reviews the standards for delineating metropolitan areas and reclassifies counties as rural or urban based on the latest census data.1 Depending on which definition year you use as your baseline, rural America can appear to be either thriving or struggling. In fact, in a 2018 article in Applied Economic Perspectives and Policy, Stephan Goetz, Mark Partridge, and Heather Stephens found that if we used the 1950 definition of “rural,” rural counties would have actually grown faster than urban ones. So much for the story of rural decline.\nThe standards based on the 2020 Census were recently updated, continuing this cycle of reclassification. To visualize how these shifts have unfolded over time, CORI mapped the counties that have “graduated” from rural to urban in the past 50 years. Take a look below."
  },
  {
    "objectID": "posts/14_nonmetro_to_metro/index.html#footnotes",
    "href": "posts/14_nonmetro_to_metro/index.html#footnotes",
    "title": "The reclassification of rural counties and what it means for rural America",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe Office of Management and Budget (OMB) does not define “rural,” but its nonmetropolitan designation is often used as a county-level proxy.↩︎"
  },
  {
    "objectID": "posts/06_pg_duckdb/index.html",
    "href": "posts/06_pg_duckdb/index.html",
    "title": "From elephant to duck!",
    "section": "",
    "text": "There are a lot of conversations — understandably — on the use of Apache Parquet, Apache Arrow and DuckDB.\nThose three open source technologies and the amount of resources that a personal laptop has now have lowered the need of using a classic RDBMS for out-of-memory-tasks for data science works, and in some cases maybe the need of using a distributed computing framework like Spark.\nLet’s see an example of how they can be used to convert a table in a PostgresSQL database to a parquet file:"
  },
  {
    "objectID": "posts/06_pg_duckdb/index.html#libraries-and-data-optional-needed",
    "href": "posts/06_pg_duckdb/index.html#libraries-and-data-optional-needed",
    "title": "From elephant to duck!",
    "section": "Libraries and data (optional) needed",
    "text": "Libraries and data (optional) needed\n\nlibrary(duckdb)\nlibrary(dplyr, warn.conflicts = FALSE)\nlibrary(dbplyr, warn.conflicts = FALSE)\n\nWe will use FCC NBM raw data with December 2023’s release. You can learn more about on FCC website.\nThe table we will be converting has a size of 102 GB (without indexes), has 888,176,676 rows and 12 columns and it is the results of importing around 440 CSVs."
  },
  {
    "objectID": "posts/06_pg_duckdb/index.html#getting-your-credentials",
    "href": "posts/06_pg_duckdb/index.html#getting-your-credentials",
    "title": "From elephant to duck!",
    "section": "Getting your credentials",
    "text": "Getting your credentials\nSince this exercise is all about converting data that is currently stored in PostgreSQL (using R), the first step in connecting to your PG database server is getting your credentials. We are assuming here that you have a .pgpass file located in your home directory (~/.pgpass).\nThe code below will assume that you have this ~/.pgpass set and that it contains a one-line connection string.\n\nget_cred &lt;- function(path_pgpass) {\n  pgpass &lt;- readLines(path_pgpass)\n  cred &lt;- unlist(strsplit(pgpass, \":\"))\n  names(cred) &lt;- c(\"host\", \"port\", \"db\", \"user\", \"pwd\")\n  return(cred)\n}\n\ncred &lt;- get_cred(\"~/.pgpass\")"
  },
  {
    "objectID": "posts/06_pg_duckdb/index.html#use-duckdb-magic-to-convert-it",
    "href": "posts/06_pg_duckdb/index.html#use-duckdb-magic-to-convert-it",
    "title": "From elephant to duck!",
    "section": "Use DuckDB magic to convert it!",
    "text": "Use DuckDB magic to convert it!\nWell, the magic is a four-step steps process:\n\nConnect to DuckDB\nGet DuckDB’s postgres extension\nConnect to your DB (with the credential we have set)\nUse DuckDB COPY specifying where and how you want it to be partitioned\n\nThis will be wrapped in one function:\n\n# yes I am terrible at naming\nfrom_elephant_to_duck &lt;- function(table_name, path_for_parquet, part1, part2) {\n  # 1. Connect to duckDB\n  con &lt;- DBI::dbConnect(duckdb())\n  DBI::dbExecute(con,\n                 sprintf(\"SET temp_directory ='%s';\", tempdir()))\n  # cleaning up after the function\n  on.exit(DBI::dbDisconnect(con), add = TRUE)\n  \n  # 2. install and load PG extension\n  DBI::dbExecute(con, \"INSTALL postgres\")\n  DBI::dbExecute(con, \"LOAD postgres\")\n\n  # 3. Connect, \"attach\" to your PG server\n  attach_string &lt;- sprintf(\n    \"ATTACH 'dbname=%s user=%s password=%s host=%s' AS db (TYPE POSTGRES, READ_ONLY)\",\n    cred[\"db\"],\n    cred[\"user\"],\n    cred[\"pwd\"],\n    cred[\"host\"]\n  )\n  DBI::dbExecute(con, attach_string)\n\n  # 4. Copy to a parquet\n  copy_string &lt;- sprintf(\"COPY \n    (SELECT * \n      FROM db.%s)\n    TO '%s' (FORMAT 'parquet', PARTITION_BY(%s, %s))\", \n    table_name, \n    path_for_parquet, \n    part1, part2)\n  DBI::dbExecute(con, copy_string)\n\n  return(invisible(path_for_parquet))\n}\n# not an improvement on this function will be to take cred has an argument\n\n\nPartitioning\nDeciding how to partition a parquet is both a data and business decisions. In this case, state_abbr and technology are good tradeoffs in terms of the overall size of each parquet file and the fast performance of common filtering and grouping operations on this data."
  },
  {
    "objectID": "posts/06_pg_duckdb/index.html#lets-do-it-and-do-some-quick-comparisons",
    "href": "posts/06_pg_duckdb/index.html#lets-do-it-and-do-some-quick-comparisons",
    "title": "From elephant to duck!",
    "section": "Let’s do it and do some quick comparisons",
    "text": "Let’s do it and do some quick comparisons\n\nstart &lt;- Sys.time()\nfrom_elephant_to_duck(\"staging.dec23\", \"dec23\", \"state_abbr\", \"technology\")\nend &lt;- Sys.time()\nend - start\n# Time difference of 58.92108 mins\n\nOn a relatively new MacBook with a wifi-internet-speed connection (probably the limiting factor here) it took a little less than an hour to run from_elephant_to_duck.\nWe can also compare our 102 GB to the size of parquet files (ofc. PG offer additional perks!):\n\ndu -sh dec23/\n# 14 G\n\nFinally, just for the pleasure, let’s run a quick query:\n\nstart &lt;- Sys.time()\ncon &lt;- DBI::dbConnect(duckdb::duckdb(), shutdown = TRUE, dbdir = tempdir())\n\nreading_string &lt;-\n  sprintf(\"read_parquet('%s/*/*/*.parquet', hive_partitioning = true)\",\n          \"dec23\")\nfcc &lt;- dplyr::tbl(con, reading_string)\n\n# check number of row\nfcc |&gt; \n  summarize(tot_rows = count(location_id)) |&gt; \n  collect()\n\n# A tibble: 1 × 1\n#    tot_rows\n#       &lt;dbl&gt;\n# 1 888176676\n\n# let's start one a bit \nstart &lt;- Sys.time()\n# this will count every location_id by state_abbr and frn\n# that have low_latency\nstart &lt;- Sys.time()\nq1 &lt;- fcc |&gt;\n  filter(low_latency == TRUE) |&gt; \n  summarize(\n    count_location =  n_distinct(location_id),\n    .by = c(state_abbr, frn)\n  )\n\nrez_q1 &lt;- collect(q1)\nend - start\n# Time difference of 4.262549 mins\n\nDBI::dbDisconnect(con)\n\nImpressive, isn’t it? We will probably dig a bit deeper on those new technologies in future blog posts, so check back soon!"
>>>>>>> 79a1402 (produced image files)
  }
]